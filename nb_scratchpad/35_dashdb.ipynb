{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building databases of published works  \n",
    "\n",
    "> Pragmatic tools for constructing databases of scientific works based on queries defined with Boolean Logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabulate queries in a spreadsheet and generate a database based on the data from those queries. \n",
    "\n",
    "**Example**:  Define a dataframe with an `id` column and a `query` column (expressing a search query in Boolean Logic):\n",
    "\n",
    "| ID | DISEASE NAME | MONDO_ID | QUERY  | \n",
    "|----|--------------|----------|--------|\n",
    "| 1 | Adult Polyglucosan Body Disease | MONDO:0009897 | adult polyglucosan body disease \\| adult polyglucosan body neuropathy\n",
    "| 2 | AGAT deficiency | MONDO:0012996 |  \"GATM deficiency\" \\| \"AGAT deficiency\" \\| \"arginine:glycine amidinotransferase deficiency\" \\| \"L-arginine:glycine amidinotransferase deficiency\"\n",
    "| 3 | Guanidinoacetate methyltransferase deficiency | MONDO:0012999 |  \"guanidinoacetate methyltransferase deficiency\" \\| \"GAMT deficiency\"\n",
    "| 4 | CLOVES Syndrome | MONDO:0013038 | \"CLOVES syndrome \\| (congenital lipomatous overgrowth) & (vascular malformation epidermal) & (nevi-spinal) & syndrome \\| (congenital lipomatous overgrowth) & (vascular malformations) & (Epidermal nevi) & ((skeletal\\|spinal) & abnormalities) \\| CLOVE syndrome \\| (congenital lipomatous overgrowth) & (vascular malformation) & (epidermal nevi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pathlib import Path\n",
    "from alhazen.utils.airtableUtils import AirtableUtils\n",
    "from alhazen.utils.searchEngineUtils import ESearchQuery, EuroPMCQuery\n",
    "from alhazen.utils.queryTranslator import QueryTranslator, QueryType\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time,sleep\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DashboardDb:\n",
    "\n",
    "  \"\"\"This class runs queries on external repositories to provide dataframes of linked corpora and papers that can be used to populate a local, medium scale database.\n",
    "\n",
    "  Functionality includes:\n",
    "\n",
    "    * Define a spreadsheet with a column of queries expressed in boolean logic\n",
    "    * Optional: Define a secondary spreadsheet with a column of subqueries expressed in boolean logic\n",
    "    * Iterate over different sources (Pubmed + European Pubmed) to execute all combinations of queries and subqueries\n",
    "    \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, name, description, loc):\n",
    "    self.name = name\n",
    "    self.description = description\n",
    "    self.loc = loc\n",
    "\n",
    "    if os.path.exists(loc) is False:\n",
    "      os.mkdir(loc)\n",
    "\n",
    "    log_path = '%s/db_log.txt' % (loc)\n",
    "    if os.path.exists(log_path) is False:\n",
    "      Path(log_path).touch()\n",
    "      \n",
    "  def execute_pubmed_queries(self, qt, qt2, api_key='', sections=['tiab']):\n",
    "    corpus_paper_list = []\n",
    "    errors = []\n",
    "    (corpus_ids, pubmed_queries) = qt.generate_queries(QueryType.pubmed, sections=sections)\n",
    "    if qt2:\n",
    "      (subset_ids, pubmed_subset_queries) = qt2.generate_queries(QueryType.pubmed, sections=sections)\n",
    "    else: \n",
    "      (subset_ids, pubmed_subset_queries) = ([0],[''])\n",
    "    for (i, q) in zip(corpus_ids, pubmed_queries):\n",
    "      for (j, sq) in zip(subset_ids, pubmed_subset_queries):\n",
    "        query = q\n",
    "        if query=='nan' or len(query)==0: \n",
    "          errors.append((i, j, query))\n",
    "          continue\n",
    "        if len(sq) > 0:\n",
    "          query = '(%s) AND (%s)'%(q, sq) \n",
    "        pmq = ESearchQuery(api_key=api_key)\n",
    "        num_found = pmq.execute_count_query(query)\n",
    "        print(num_found)\n",
    "        if num_found>0:\n",
    "          pmids = pmq.execute_query(query)\n",
    "          sleep(0.5) # Sleep for half a second\n",
    "          for id in tqdm(pmids):\n",
    "            corpus_paper_list.append((id, i, 'pubmed', j))\n",
    "    return corpus_paper_list\n",
    "\n",
    "  def execute_epmc_queries_on_sections(self, qt, qt2, sections=['paper_title', 'ABSTRACT'], \n",
    "                                       extra_columns=[\"id\", \"source\", \"doi\", 'title', 'pubYear', 'abstractText', 'pubType']):\n",
    "    corpus_paper_list = []\n",
    "    epmc_errors = []\n",
    "    (corpus_ids, epmc_queries) = qt.generate_queries(QueryType.epmc, sections=sections)\n",
    "    if qt2:\n",
    "      (subset_ids, epmc_subset_queries) = qt2.generate_queries(QueryType.epmc, sections=sections)\n",
    "    else: \n",
    "      (subset_ids, epmc_subset_queries) = ([0],[''])\n",
    "    for (i, q) in zip(corpus_ids, epmc_queries):\n",
    "      for (j, sq) in zip(subset_ids, epmc_subset_queries):\n",
    "        query = q\n",
    "        if query is None or query=='nan' or len(query)==0: \n",
    "          continue\n",
    "        if len(sq) > 0:\n",
    "          query = '(%s) AND (%s)'%(q, sq) \n",
    "        epmcq = EuroPMCQuery()\n",
    "        #try:\n",
    "        numFound, epmc_pmids = epmcq.run_empc_query(query, extra_columns=extra_columns)\n",
    "        for row in tqdm(epmc_pmids):\n",
    "            tup = [row[0], i, 'epmc', j, row[1]]\n",
    "            if len(row)>2:\n",
    "                tup.extend(row[2:])\n",
    "            corpus_paper_list.append(tup)\n",
    "        #except Exception as e:\n",
    "        #  epmc_errors.append((i, j, query, e))\n",
    "    return corpus_paper_list, epmc_errors\n",
    "\n",
    "  def check_query_terms(self, qt, qt2=None, pubmed_api_key=''):\n",
    "    pmq = ESearchQuery(api_key=pubmed_api_key)\n",
    "    terms = set()\n",
    "    for t in qt.terms2id.keys():\n",
    "        terms.add(t)\n",
    "    if qt2 is not None:\n",
    "        for t2 in qt2.terms2id.keys():\n",
    "            terms.add(t2)\n",
    "    check_table = {} \n",
    "    for t in tqdm(terms):\n",
    "        (is_ok, t2, c) = pmq._check_query_phrase(t)\n",
    "        check_table[t] = (is_ok, c)\n",
    "    return check_table\n",
    "\n",
    "  def airtable_to_corpus_dataframes(self, at_key, at_file, at_sheets, \n",
    "                                    extra_columns=[\"id\", \"source\", \"doi\", 'title', 'pubYear', 'abstractText', 'pubType']):\n",
    "    atu = AirtableUtils(at_key)\n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    for sn, id_col, query_col, col_map, sections in at_sheets: \n",
    "        cdf = atu.read_airtable(at_file, sn)\n",
    "        cdf = cdf.rename(columns={id_col:'ID', query_col:'QUERY'})\n",
    "        cdf = cdf.rename(columns=col_map)\n",
    "        cdf = cdf.fillna('').rename(\n",
    "            columns={c:re.sub('[\\s\\(\\)]','_', c.upper()) for c in cdf.columns}\n",
    "            )\n",
    "        cdf.QUERY = [re.sub('^http[s]*://', '', r.QUERY) if r.QUERY[:4]=='http' else r.QUERY \n",
    "                     for i,r in cdf.iterrows()] \n",
    "        cdf.QUERY = [re.sub('/$', '', r.QUERY.strip())  \n",
    "                        for i,r in cdf.iterrows()] \n",
    "        df1 = pd.concat([df1, cdf])\n",
    "        qt = QueryTranslator(cdf, 'ID', 'QUERY')\n",
    "        paper_list, errors = self.execute_epmc_queries_on_sections(qt, None, sections=sections)\n",
    "        l = [tup if re.match('\\d',tup[0]) else (-1, tup[1], tup[2], tup[3], tup[4]) for tup in paper_list]\n",
    "        cols = ['ID_PAPER', 'ID_CORPUS', 'SOURCE', 'SUBSET_CODE', 'DOI']\n",
    "        cols.extend(extra_columns)\n",
    "        temp = pd.DataFrame(paper_list, columns=cols)\n",
    "        df2 = pd.concat([df2, temp.drop(columns=extra_columns).drop_duplicates()])\n",
    "        if len(extra_columns)>0:\n",
    "            df3 = pd.concat([df3, temp.drop(columns=['ID_CORPUS','SOURCE', 'SUBSET_CODE']).drop_duplicates()])\n",
    "    df1.fillna('', inplace=True)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2.fillna('', inplace=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    df3.fillna('', inplace=True)\n",
    "    df3 = df3.reset_index(drop=True).drop_duplicates()\n",
    "    \n",
    "    return df1, df2, df3\n",
    "  \n",
    "  def build_corpus_dataframes(self, cdf, id_col, query_col, col_map={}, sections=['TITLE','ABSTRACT'], \n",
    "                              extra_columns=[\"id\", \"source\", \"doi\", 'title', 'pubYear', 'abstractText', 'pubType']):\n",
    "    \n",
    "    cdf = cdf.rename(columns={id_col:'ID', query_col:'QUERY'})\n",
    "    cdf = cdf.rename(columns=col_map)\n",
    "    cdf = cdf.fillna('').rename(\n",
    "        columns={c:re.sub('[\\s\\(\\)]','_', c.upper()) for c in cdf.columns}\n",
    "        )\n",
    "    cdf.QUERY = [re.sub('^http[s]*://', '', r.QUERY) if r.QUERY[:4]=='http' else r.QUERY \n",
    "                  for i,r in cdf.iterrows()] \n",
    "    cdf.QUERY = [re.sub('/$', '', r.QUERY.strip())  \n",
    "                    for i,r in cdf.iterrows()] \n",
    "    qt = QueryTranslator(cdf, 'ID', 'QUERY')\n",
    "    paper_list, errors = self.execute_epmc_queries_on_sections(qt, None, sections=sections)\n",
    "    l = [tup if re.match('\\d',tup[0]) else (-1, tup[1], tup[2], tup[3], tup[4]) for tup in paper_list]\n",
    "    cols = ['ID_PAPER', 'ID_CORPUS', 'SOURCE', 'SUBSET_CODE', 'DOI']\n",
    "    cols.extend(extra_columns)\n",
    "    temp = pd.DataFrame(paper_list, columns=cols)\n",
    "    df2 = temp.drop(columns=extra_columns).drop_duplicates()\n",
    "    if len(extra_columns)>0:\n",
    "        df3 = temp.drop(columns=['ID_CORPUS','SOURCE', 'SUBSET_CODE']).drop_duplicates()\n",
    "    cdf.fillna('', inplace=True)\n",
    "    df2.fillna('', inplace=True)\n",
    "    df3.fillna('', inplace=True)\n",
    "    return cdf, df2, df3\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>QUERY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cryo-Electron Tomography</td>\n",
       "      <td>Cryoelectron Tomography | Cryo Electron Tomogr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      NAME  \\\n",
       "0   1  Cryo-Electron Tomography   \n",
       "\n",
       "                                               QUERY  \n",
       "0  Cryoelectron Tomography | Cryo Electron Tomogr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "EM_QUERIES_TSV = '''\n",
    "ID,NAME,QUERY\n",
    "0,Hierarchical phase-contrast tomography,Hierarchical phase-contrast tomography | HIP-CT | Hierarchical phase contrast tomography\n",
    "1,Cryo-Electron Tomography,Cryoelectron Tomography | Cryo Electron Tomography | Cryo-Electron Tomography | Cryo-ET | CryoET\n",
    "2,Volume Electron Microscopy,Volume Electron Microscopy | Volume EM | (serial section & (electron microscopy | EM | transmission electron microscopy | TEM | scanning electron microscopy | SEM | electron tomography )) | (serial block-face & (SEM | scanning electron microscopy)) | (focused ion beam & (SEM | scanning electron microscopy)) | (automated serial & (TEM | transmission electron microscopy)) | ( massively parallel imaging & (SEM | scanning electron microscopy)) | multibeam SEM | FAST-SEM | cryo-TEM\n",
    "'''\n",
    "EM_QUERIES_TSV = '''\n",
    "ID,NAME,QUERY\n",
    "1,Cryo-Electron Tomography,Cryoelectron Tomography | Cryo Electron Tomography | Cryo-Electron Tomography | Cryo-ET | CryoET\n",
    "'''\n",
    "\n",
    "em_queries_df = pd.read_csv(StringIO(EM_QUERIES_TSV), sep=',')\n",
    "em_queries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2283.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1101.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ebi.ac.uk/europepmc/webservices/rest/search?format=JSON&pageSize=1000&synonym=TRUE&resultType=core&query=((TITLE:\"Cryoelectron Tomography\" OR ABSTRACT:\"Cryoelectron Tomography\" OR METHODS:\"Cryoelectron Tomography\") OR (TITLE:\"Cryo Electron Tomography\" OR ABSTRACT:\"Cryo Electron Tomography\" OR METHODS:\"Cryo Electron Tomography\") OR (TITLE:\"Cryo-Electron Tomography\" OR ABSTRACT:\"Cryo-Electron Tomography\" OR METHODS:\"Cryo-Electron Tomography\") OR (TITLE:\"Cryo-ET\" OR ABSTRACT:\"Cryo-ET\" OR METHODS:\"Cryo-ET\") OR (TITLE:\"CryoET\" OR ABSTRACT:\"CryoET\" OR METHODS:\"CryoET\")), 2431 European PMC PAPERS FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:35<00:00, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Returning 2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2431/2431 [00:00<00:00, 287723.72it/s]\n"
     ]
    }
   ],
   "source": [
    "db = DashboardDb('em_literature', 'EuropePMC papers based on EM keywords', '/Users/gburns/Documents/2023H2/cryoet_portal_rocrates/EM_LITERATURE_DB')\n",
    "df1, df2, df3 = db.build_corpus_dataframes(em_queries_df, 'ID', 'QUERY', sections=['TITLE','ABSTRACT', 'METHODS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_PAPER</th>\n",
       "      <th>DOI</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>pubYear</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>pubType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10620151</td>\n",
       "      <td>10.1046/j.1365-2818.2000.00629.x</td>\n",
       "      <td>10620151</td>\n",
       "      <td>MED</td>\n",
       "      <td>10.1046/j.1365-2818.2000.00629.x</td>\n",
       "      <td>Soft X-ray microscopy with a cryo scanning tra...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Using a cryo scanning transmission X-ray micro...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10675296</td>\n",
       "      <td>10.1006/jsbi.1999.4204</td>\n",
       "      <td>10675296</td>\n",
       "      <td>MED</td>\n",
       "      <td>10.1006/jsbi.1999.4204</td>\n",
       "      <td>Cryo-electron tomography of neurospora mitocho...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Cryo-electron tomography was used to study the...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10806087</td>\n",
       "      <td>10.1006/jsbi.2000.4215</td>\n",
       "      <td>10806087</td>\n",
       "      <td>MED</td>\n",
       "      <td>10.1006/jsbi.2000.4215</td>\n",
       "      <td>The cell surface glycoprotein layer of the ext...</td>\n",
       "      <td>2000</td>\n",
       "      <td>We have studied the surface layer (S-layer) of...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11516947</td>\n",
       "      <td>10.1016/s0960-9822(01)00349-9</td>\n",
       "      <td>11516947</td>\n",
       "      <td>MED</td>\n",
       "      <td>10.1016/s0960-9822(01)00349-9</td>\n",
       "      <td>FhuA-mediated phage genome transfer into lipos...</td>\n",
       "      <td>2001</td>\n",
       "      <td>&lt;h4&gt;Background&lt;/h4&gt;The transfer of phage genom...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12160700</td>\n",
       "      <td>10.1016/s1047-8477(02)00020-5</td>\n",
       "      <td>12160700</td>\n",
       "      <td>MED</td>\n",
       "      <td>10.1016/s1047-8477(02)00020-5</td>\n",
       "      <td>Use of frozen-hydrated axonemes to assess imag...</td>\n",
       "      <td>2002</td>\n",
       "      <td>Using a 400-kV cryoelectron microscope, we hav...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>PPR93207</td>\n",
       "      <td>10.1101/777854</td>\n",
       "      <td>PPR93207</td>\n",
       "      <td>PPR</td>\n",
       "      <td>10.1101/777854</td>\n",
       "      <td>Boiling Acid Mimics Intracellular Giant Virus ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>&lt;h4&gt;Summary&lt;/h4&gt; Since their discovery, giant ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>PPR94004</td>\n",
       "      <td>10.1101/783373</td>\n",
       "      <td>PPR94004</td>\n",
       "      <td>PPR</td>\n",
       "      <td>10.1101/783373</td>\n",
       "      <td>Crystal structure of human PACRG in complex wi...</td>\n",
       "      <td>2019</td>\n",
       "      <td>In human, the Parkin Co-Regulated Gene (PACRG)...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>PPR94275</td>\n",
       "      <td>10.1101/786715</td>\n",
       "      <td>PPR94275</td>\n",
       "      <td>PPR</td>\n",
       "      <td>10.1101/786715</td>\n",
       "      <td>Bacterial flagellar motor PL-ring disassembly ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>The bacterial flagellar motor is an amazing na...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>PPR95335</td>\n",
       "      <td>10.1101/797514</td>\n",
       "      <td>PPR95335</td>\n",
       "      <td>PPR</td>\n",
       "      <td>10.1101/797514</td>\n",
       "      <td>Fully automated, sequential focused ion beam m...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cryo-electron tomography (cryoET) has become a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>PPR95364</td>\n",
       "      <td>10.1101/797506</td>\n",
       "      <td>PPR95364</td>\n",
       "      <td>PPR</td>\n",
       "      <td>10.1101/797506</td>\n",
       "      <td>Automated cryo-lamella preparation for high-th...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cryo-transmission electron tomography (cryo-ET...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2431 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID_PAPER                               DOI        id source  \\\n",
       "0     10620151  10.1046/j.1365-2818.2000.00629.x  10620151    MED   \n",
       "1     10675296            10.1006/jsbi.1999.4204  10675296    MED   \n",
       "2     10806087            10.1006/jsbi.2000.4215  10806087    MED   \n",
       "3     11516947     10.1016/s0960-9822(01)00349-9  11516947    MED   \n",
       "4     12160700     10.1016/s1047-8477(02)00020-5  12160700    MED   \n",
       "...        ...                               ...       ...    ...   \n",
       "2426  PPR93207                    10.1101/777854  PPR93207    PPR   \n",
       "2427  PPR94004                    10.1101/783373  PPR94004    PPR   \n",
       "2428  PPR94275                    10.1101/786715  PPR94275    PPR   \n",
       "2429  PPR95335                    10.1101/797514  PPR95335    PPR   \n",
       "2430  PPR95364                    10.1101/797506  PPR95364    PPR   \n",
       "\n",
       "                                   doi  \\\n",
       "0     10.1046/j.1365-2818.2000.00629.x   \n",
       "1               10.1006/jsbi.1999.4204   \n",
       "2               10.1006/jsbi.2000.4215   \n",
       "3        10.1016/s0960-9822(01)00349-9   \n",
       "4        10.1016/s1047-8477(02)00020-5   \n",
       "...                                ...   \n",
       "2426                    10.1101/777854   \n",
       "2427                    10.1101/783373   \n",
       "2428                    10.1101/786715   \n",
       "2429                    10.1101/797514   \n",
       "2430                    10.1101/797506   \n",
       "\n",
       "                                                  title pubYear  \\\n",
       "0     Soft X-ray microscopy with a cryo scanning tra...    2000   \n",
       "1     Cryo-electron tomography of neurospora mitocho...    2000   \n",
       "2     The cell surface glycoprotein layer of the ext...    2000   \n",
       "3     FhuA-mediated phage genome transfer into lipos...    2001   \n",
       "4     Use of frozen-hydrated axonemes to assess imag...    2002   \n",
       "...                                                 ...     ...   \n",
       "2426  Boiling Acid Mimics Intracellular Giant Virus ...    2019   \n",
       "2427  Crystal structure of human PACRG in complex wi...    2019   \n",
       "2428  Bacterial flagellar motor PL-ring disassembly ...    2019   \n",
       "2429  Fully automated, sequential focused ion beam m...    2019   \n",
       "2430  Automated cryo-lamella preparation for high-th...    2019   \n",
       "\n",
       "                                           abstractText pubType  \n",
       "0     Using a cryo scanning transmission X-ray micro...          \n",
       "1     Cryo-electron tomography was used to study the...          \n",
       "2     We have studied the surface layer (S-layer) of...          \n",
       "3     <h4>Background</h4>The transfer of phage genom...          \n",
       "4     Using a 400-kV cryoelectron microscope, we hav...          \n",
       "...                                                 ...     ...  \n",
       "2426  <h4>Summary</h4> Since their discovery, giant ...          \n",
       "2427  In human, the Parkin Co-Regulated Gene (PACRG)...          \n",
       "2428  The bacterial flagellar motor is an amazing na...          \n",
       "2429  Cryo-electron tomography (cryoET) has become a...          \n",
       "2430  Cryo-transmission electron tomography (cryo-ET...          \n",
       "\n",
       "[2431 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test -f /tmp/tmp.db && rm /tmp/tmp.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../sql/schema.sql | sqlite3 /tmp/alhazen/tmp.db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mm(graph):\n",
    "  graphbytes = graph.encode(\"ascii\")\n",
    "  base64_bytes = base64.b64encode(graphbytes)\n",
    "  base64_string = base64_bytes.decode(\"ascii\")\n",
    "  display(\n",
    "    Image(\n",
    "      url=\"https://mermaid.ink/img/\"\n",
    "      + base64_string\n",
    "    )\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Work in module alhazen.schema_sqla:\n",
      "\n",
      "class Work(InformationContentEntity)\n",
      " |  Work(**kwargs)\n",
      " |  \n",
      " |  A published work\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Work\n",
      " |      InformationContentEntity\n",
      " |      NamedThing\n",
      " |      Entity\n",
      " |      sqlalchemy.orm.decl_api.Base\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      A simple constructor that allows initialization from kwargs.\n",
      " |      \n",
      " |      Sets attributes on the constructed instance using the names and\n",
      " |      values in ``kwargs``.\n",
      " |      \n",
      " |      Only keys that are present as\n",
      " |      attributes of the instance's class are allowed. These could be,\n",
      " |      for example, any mapped columns or relationships.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  abstract\n",
      " |  \n",
      " |  authors\n",
      " |  \n",
      " |  creation_date\n",
      " |  \n",
      " |  format\n",
      " |  \n",
      " |  full_text\n",
      " |  \n",
      " |  has_part\n",
      " |  \n",
      " |  id\n",
      " |  \n",
      " |  iri\n",
      " |  \n",
      " |  license\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  rights\n",
      " |  \n",
      " |  title\n",
      " |  \n",
      " |  type_rel\n",
      " |  \n",
      " |  xref_rel\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __mapper__ = <Mapper at 0x10f373990; Work>\n",
      " |  \n",
      " |  __mapper_args__ = {'concrete': True}\n",
      " |  \n",
      " |  __table__ = Table('Work', MetaData(), Column('id', Text(), t...Column(...\n",
      " |  \n",
      " |  __tablename__ = 'Work'\n",
      " |  \n",
      " |  type = ColumnAssociationProxyInstance(AssociationProxy('type_rel', 'ty...\n",
      " |  \n",
      " |  xref = ColumnAssociationProxyInstance(AssociationProxy('xref_rel', 'xr...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:\n",
      " |  \n",
      " |  __abstract__ = True\n",
      " |  \n",
      " |  metadata = MetaData()\n",
      " |  \n",
      " |  registry = <sqlalchemy.orm.decl_api.registry object>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Work(id=100,title=Test,abstract=Test abstract,full_text=None,license=None,rights=None,format=None,creation_date=None,name=None,iri=10.1234/1234,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from alhazen.schema_sqla import Work\n",
    "help(Work)\n",
    "\n",
    "Work(id=100, title='Test', abstract='Test abstract', iri='10.1234/1234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:////tmp/alhazen/tmp.db\")\n",
    "session_class = sessionmaker(bind=engine)\n",
    "session = session_class()\n",
    "p = Work(id=100, title='Test', abstract='Test abstract', iri='10.1234/1234')\n",
    "session.add(p)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /tmp/alhazen/tmp.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100|Test|Test abstract|||||||10.1234/1234\n"
     ]
    }
   ],
   "source": [
    "!sqlite3 /tmp/alhazen/tmp.db \"SELECT * FROM Work;\" \".exit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in session.query(Work).where(Work.id!=100):\n",
    "    print(p.title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
