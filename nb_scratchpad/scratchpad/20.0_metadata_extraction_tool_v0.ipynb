{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods Metadata Extraction Tool   \n",
    "\n",
    "> Langchain tools that execute zero-shot extraction over a local database of full text papers previously imported into our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tools.metadata_extraction_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import local_resources.linkml as linkml\n",
    "\n",
    "from alhazen.core import OllamaRunner, PromptTemplateRegistry, get_langchain_llm, get_cached_gguf, get_langchain_embeddings, GGUF_LOOKUP_URL, MODEL_TYPE\n",
    "from alhazen.utils.airtableUtils import AirtableUtils\n",
    "from alhazen.utils.searchEngineUtils import ESearchQuery, EuroPMCQuery\n",
    "from alhazen.utils.langchain_utils import suppress_stdout_stderr\n",
    "from alhazen.utils.output_parsers import JsonEnclosedByTextOutputParser\n",
    "\n",
    "from alhazen.utils.queryTranslator import QueryTranslator, QueryType\n",
    "from alhazen.utils.jats_text_extractor import NxmlDoc\n",
    "from alhazen.utils.ceifns_db import *\n",
    "\n",
    "from alhazen.schema_sqla import ScientificKnowledgeCollection, ScientificKnowledgeExpression, \\\n",
    "    ScientificKnowledgeFragment, Note, ScientificKnowledgeCollection, \\\n",
    "    ScientificKnowledgeExpression, ScientificKnowledgeCollectionHasMembers, \\\n",
    "    ScientificKnowledgeItem, ScientificKnowledgeExpressionHasRepresentation, \\\n",
    "    ScientificKnowledgeFragment, ScientificKnowledgeItemHasPart, \\\n",
    "    InformationResource\n",
    "\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema import OutputParserException\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.chains.combine_documents import collapse_docs, split_list_of_docs\n",
    "from langchain.llms import LlamaCpp \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "from importlib_resources import files\n",
    "import local_resources.prompt_elements as prompt_elements\n",
    "\n",
    "from bs4 import BeautifulSoup,Tag,Comment,NavigableString\n",
    "from datetime import datetime\n",
    "from importlib_resources import files\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import requests\n",
    "from sqlalchemy import create_engine, exists\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from time import time,sleep\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus, quote, unquote\n",
    "from urllib.error import URLError, HTTPError\n",
    "import uuid\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 10)\n",
    "#pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MetadataExtractionTool:\n",
    "    '''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\n",
    "\n",
    "    lldb = None\n",
    "    step_identification_prompt_template = None\n",
    "    metadata_extraction_prompt_template = None\n",
    "    methodology = None\n",
    "    method_goal = None\n",
    "    all_protocol_steps = None\n",
    "    all_protocol_step_codes = None\n",
    "    metadata_specs: []\n",
    "    run_name = None\n",
    "    \n",
    "    def __init__(self, lldb, prompt_element_spec_name, llm_model='mixtral'):\n",
    "        self.lldb = lldb\n",
    "        if self.lldb.session is None:\n",
    "            session_class = sessionmaker(bind=self.lldb.engine)\n",
    "            self.lldb.session = session_class()\n",
    "\n",
    "        pts = PromptTemplateRegistry()\n",
    "        pts.load_prompts_from_yaml('metadata_extraction.yaml')\n",
    "        self.step_identification_prompt_template = pts.get_prompt_template('protocol step identification').generate_llama2_prompt_template()\n",
    "        self.metadata_extraction_prompt_template = pts.get_prompt_template('metadata extraction').generate_llama2_prompt_template()\n",
    "        self.run_name = 'metadata_extraction_' + re.sub(' ','_',prompt_element_spec_name)\n",
    "\n",
    "        # loading the additional elements from the yaml file\n",
    "        # Note that there is an implicit assumption that the additional elements are formatted correctly. \n",
    "        # This code will throw an exception if the yaml file is not formatted correctly.\n",
    "        prompt_elements_yaml = files(prompt_elements).joinpath('metadata_extraction.yaml').read_text()\n",
    "        prompt_elements_dict = yaml.safe_load(prompt_elements_yaml).get(prompt_element_spec_name)\n",
    "        self.method_goal = prompt_elements_dict['method goal']\n",
    "        self.methodology = prompt_elements_dict['methodology']\n",
    "        self.all_protocol_steps = prompt_elements_dict['all protocol steps']\n",
    "        self.all_protocol_step_codes = prompt_elements_dict['all protocol step codes']\n",
    "        self.metadata_specs = prompt_elements_dict['metadata specs']\n",
    "\n",
    "        self.ollr = OllamaRunner(llm_model)\n",
    "        self.llm  = self.ollr.llm\n",
    "\n",
    "        self.protocol_step_id_lcel = self.step_identification_prompt_template | self.llm | JsonEnclosedByTextOutputParser()\n",
    "        self.extract_lcel = self.metadata_extraction_prompt_template | self.llm | JsonEnclosedByTextOutputParser()\n",
    "\n",
    "    def run(self, paper_id, section_name, item_type='JATSFullText'):\n",
    "        '''Runs the metadata extraction pipeline over a specified paper.'''\n",
    "        \n",
    "        # Load the paper + fragments from the local database\n",
    "        fragments = self.lldb.list_fragments_for_paper(paper_id, item_type)\n",
    "    \n",
    "        for f in fragments:\n",
    "            if len(f.content) <= 50:\n",
    "                continue\n",
    "            \n",
    "            if section_name not in f.name.lower():\n",
    "                continue\n",
    "            \n",
    "            s1 = {'section_text':f.content,\n",
    "                  'methodology': self.methodology,\n",
    "                  'method_goal': self.method_goal,\n",
    "                  'all_protocol_steps': self.all_protocol_steps,\n",
    "                  'all_protocol_step_codes': self.all_protocol_step_codes\n",
    "                 }\n",
    "            protocol_step = None\n",
    "            attempts = 0\n",
    "            while protocol_step is None and attempts < 5:\n",
    "                try: \n",
    "                    #with suppress_stdout_stderr():\n",
    "                    out1 = self.protocol_step_id_lcel.invoke(s1, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "                    if out1 is not None:\n",
    "                        protocol_step = out1.get('protocol_step', None)\n",
    "                    else: \n",
    "                        protocol_step = 'X'\n",
    "                except OutputParserException as e:\n",
    "                    attempts += 1\n",
    "                    print(e) \n",
    "                    print('Retrying...')\n",
    "                    \n",
    "            #print('\\t'+protocol_step)  \n",
    "            for spec in self.metadata_specs:\n",
    "                if protocol_step not in spec.get('step') :\n",
    "                    continue\n",
    "                s2 = {'section_text':f.content, \n",
    "                      'methodology': self.methodology,\n",
    "                      'method_goal': self.method_goal,\n",
    "                      'metadata_specification': spec.get('spec'), \n",
    "                      'metadata_name': spec.get('name') }\n",
    "                \n",
    "                try:\n",
    "                    #with suppress_stdout_stderr():\n",
    "                    out2 = self.extract_lcel.invoke(s2, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "                except OutputParserException as e:\n",
    "                    continue\n",
    "                if out2 is not None:\n",
    "                    # serialize out2 as json\n",
    "                    note_content = json.dumps(out2)\n",
    "                    \n",
    "                    # add a fragment to the database                    \n",
    "                    n = Note(\n",
    "                        id=uuid.uuid4().hex[0:10],\n",
    "                        type='NoteAboutFragment', \n",
    "                        name=self.run_name,\n",
    "                        content=note_content, \n",
    "                        creation_date=datetime.now(), \n",
    "                        format='json')\n",
    "                    n.is_about.append(f)\n",
    "                    self.lldb.session.add(n)\n",
    "                    self.lldb.session.flush()\n",
    "\n",
    "        # commit the changes to the database\n",
    "        self.lldb.session.commit()\n",
    "\n",
    "    def tabulate_fragments(self, paper_id):\n",
    "        q1 = self.lldb.session.query(ScientificKnowledgeItem) \\\n",
    "            .filter(ScientificKnowledgeExpression.id == ScientificKnowledgeExpressionHasRepresentation.ScientificKnowledgeExpression_id) \\\n",
    "            .filter(ScientificKnowledgeExpressionHasRepresentation.has_representation_id == ScientificKnowledgeItem.id) \\\n",
    "            .filter(ScientificKnowledgeItem.type == 'FullTextPaper') \\\n",
    "            .filter(ScientificKnowledgeExpression.id.like('%'+paper_id+'%')) \n",
    "        i = q1.first()\n",
    "        l = []  \n",
    "        for f in i.has_part:\n",
    "            for n in f.has_notes:\n",
    "                if n.name == self.run_name:\n",
    "                    d = json.loads(n.content)\n",
    "                    d['section'] = f.name\n",
    "                    d['offset'] = f.offset\n",
    "                    d['length'] = f.length\n",
    "                    l.append(d)\n",
    "        df = pd.DataFrame(l)\n",
    "        df_pivot = df.pivot(index='metadata_name', columns=['offset', 'section'], values='metadata_value').fillna('')\n",
    "        return df, df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
