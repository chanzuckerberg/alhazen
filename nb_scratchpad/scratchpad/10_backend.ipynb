{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langserve Backend Endpoint \n",
    "\n",
    "> A server-side delivery of langchain agents and chains (based on externally defined `add_routes()` function calls.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code as the following:\n",
    "\n",
    "```\n",
    "python -m alhazen.backend \n",
    "```\n",
    "\n",
    "The system will include additional endpoints defined by subclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "from uuid import UUID\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.globals import set_debug\n",
    "from langchain.schema.embeddings import Embeddings\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "\n",
    "from langserve import add_routes\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "import os\n",
    "from operator import itemgetter\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Hack to fix Incorrect formatting for Llama Chat models (including Mixtral)\n",
    "from alhazen.utils.langchain_utils import ChatPromptValue_to_string\n",
    "from langchain.prompts.chat import ChatPromptValue\n",
    "ChatPromptValue.to_string = ChatPromptValue_to_string\n",
    "\n",
    "from alhazen.langserve.chat import ChatRequest, get_chain_for_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def get_embeddings_model() -> Embeddings:\n",
    "    model_name = \"BAAI/bge-large-en\"\n",
    "    model_kwargs = {\"device\": \"mps\"}\n",
    "    encode_kwargs = {\"normalize_embeddings\": True}\n",
    "    return HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "def get_retriever() -> BaseRetriever:    \n",
    "    pgvector_docstore = PGVector.from_existing_index(\n",
    "        embedding=get_embeddings_model(),\n",
    "        collection_name='ScienceKnowledgeItem_CitationRecord')\n",
    "    return pgvector_docstore.as_retriever(search_kwargs=dict(k=6))\n",
    "\n",
    "def get_llm() -> BaseRetriever:\n",
    "    llm = ChatOllama(model=\"mixtral\", streaming=True, temperature=0.1)\n",
    "    return llm\n",
    "\n",
    "'''class SendFeedbackBody(BaseModel):\n",
    "    run_id: UUID\n",
    "    key: str = \"user_score\"\n",
    "\n",
    "    score: Union[float, int, bool, None] = None\n",
    "    feedback_id: Optional[UUID] = None\n",
    "    comment: Optional[str] = None\n",
    "\n",
    "\n",
    "@app.post(\"/feedback\")\n",
    "async def send_feedback(body: SendFeedbackBody):\n",
    "    client.create_feedback(\n",
    "        body.run_id,\n",
    "        body.key,\n",
    "        score=body.score,\n",
    "        comment=body.comment,\n",
    "        feedback_id=body.feedback_id,\n",
    "    )\n",
    "    return {\"result\": \"posted feedback successfully\", \"code\": 200}\n",
    "\n",
    "\n",
    "class UpdateFeedbackBody(BaseModel):\n",
    "    feedback_id: UUID\n",
    "    score: Union[float, int, bool, None] = None\n",
    "    comment: Optional[str] = None\n",
    "\n",
    "\n",
    "@app.patch(\"/feedback\")\n",
    "async def update_feedback(body: UpdateFeedbackBody):\n",
    "    feedback_id = body.feedback_id\n",
    "    if feedback_id is None:\n",
    "        return {\n",
    "            \"result\": \"No feedback ID provided\",\n",
    "            \"code\": 400,\n",
    "        }\n",
    "    client.update_feedback(\n",
    "        feedback_id,\n",
    "        score=body.score,\n",
    "        comment=body.comment,\n",
    "    )\n",
    "    return {\"result\": \"patched feedback successfully\", \"code\": 200}\n",
    "'''\n",
    "\n",
    "# TODO: Update when async API is available\n",
    "async def _arun(func, *args, **kwargs):\n",
    "    return await asyncio.get_running_loop().run_in_executor(None, func, *args, **kwargs)\n",
    "\n",
    "async def aget_trace_url(run_id: str) -> str:\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            await _arun(client.read_run, run_id)\n",
    "            break\n",
    "        except langsmith.utils.LangSmithError:\n",
    "            await asyncio.sleep(1**i)\n",
    "\n",
    "    if await _arun(client.run_is_shared, run_id):\n",
    "        return await _arun(client.read_run_shared_link, run_id)\n",
    "    return await _arun(client.share_run, run_id)\n",
    "\n",
    "class GetTraceBody(BaseModel):\n",
    "    run_id: UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Alhazen Server\",\n",
    "    version=\"0.0.1\",\n",
    "    description=\"An api server using Langserve to support the Alhazen agent's tools.\",\n",
    ")\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    "    expose_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.post(\"/get_trace\")\n",
    "async def get_trace(body: GetTraceBody):\n",
    "    run_id = body.run_id\n",
    "    if run_id is None:\n",
    "        return {\n",
    "            \"result\": \"No LangSmith run ID provided\",\n",
    "            \"code\": 400,\n",
    "        }\n",
    "    return await aget_trace_url(str(run_id))\n",
    "\n",
    "if os.environ.get('ALHAZEN_DB_NAME') is not None:\n",
    "    os.environ['PGVECTOR_CONNECTION_STRING'] = \"postgresql+psycopg2://localhost:5432/\"+os.environ['ALHAZEN_DB_NAME']\n",
    "    \n",
    "    client = Client()\n",
    "\n",
    "    # Adds routes to the app for using the chain under:\n",
    "    # /invoke\n",
    "    # /batch\n",
    "    # /stream\n",
    "    add_routes(app, \\\n",
    "            get_chain_for_app(get_llm(), get_retriever()), \\\n",
    "            path=\"/chat\", \\\n",
    "            input_type=ChatRequest, \\\n",
    "            config_keys=[\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| export \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#| output: false\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALHAZEN_DB_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     uvicorn\u001b[38;5;241m.\u001b[39mrun(app, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8080\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "#| output: false\n",
    "\n",
    "if __name__ == \"__main__\" and os.environ.get('ALHAZEN_DB_NAME') is not None:\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"localhost\", port=8080)\n",
    "else: \n",
    "    print('Please set `ALHAZEN_DB_NAME` to name of locally-installed PostGresQL database to be used with this chat client.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
