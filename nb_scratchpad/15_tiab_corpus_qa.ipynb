{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA on a corpus of PDF files.\n",
    "\n",
    "> Building a simple chatbot to allow the user to ask questions about a collection of PDF files (e.g., grant proposals). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tools.tiab_corpus_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gburns/miniconda3/envs/tmp_llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "from llama_index import Document, ServiceContext, set_global_service_context\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "    \n",
    "from alhazen.core import get_llamaindex_llm\n",
    "\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index import download_loader\n",
    "\n",
    "import fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "from llama_index import download_loader\n",
    "PyMuPDFReader = download_loader(\"PyMuPDFReader\")\n",
    "\n",
    "class FileCollectionChatBot:\n",
    "\n",
    "    def __init__(self, \n",
    "                doc_dir, \n",
    "                llm_name, \n",
    "                embed_model_name=\"BAAI/bge-small-en-v1.5\", \n",
    "                sentence_window_size=10):\n",
    "\n",
    "        self.embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "        \n",
    "        if doc_dir[-1:] != '/':\n",
    "            doc_dir += '/'\n",
    "        self.doc_dir = doc_dir\n",
    "\n",
    "        self.llm = get_llamaindex_llm(llm_name)     \n",
    "\n",
    "        # create the sentence window node parser w/ default settings\n",
    "        self.node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "            window_size=sentence_window_size,\n",
    "            window_metadata_key=\"window\",\n",
    "            original_text_metadata_key=\"original_text\",\n",
    "            )\n",
    "        self.embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "\n",
    "        # create a service context\n",
    "        self.service_context = ServiceContext.from_defaults(\n",
    "            llm=self.llm,\n",
    "            embed_model=self.embed_model,\n",
    "            node_parser=self.node_parser)\n",
    "        \n",
    "        # List all pdf files in doc_dir by walking the whole directory tree\n",
    "        pdf_file_list = []\n",
    "        for root, dirs, files in os.walk(self.doc_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    pdf_file_list.append(os.path.join(root, file))\n",
    "        \n",
    "        self.loader = PyMuPDFReader()\n",
    "        \n",
    "        # Load each PDF block as a document\n",
    "        documents = []\n",
    "        print('Loading Documents...')\n",
    "        for file in tqdm(pdf_file_list):\n",
    "            pdf_documents = self.loader.load_data(file_path=file, metadata=True)\n",
    "            documents.extend(pdf_documents)\n",
    "        print('Loading Complete!')\n",
    "\n",
    "        self.index = VectorStoreIndex.from_documents(documents, service_context=self.service_context)\n",
    "        self.query_engine = self.index.as_query_engine()\n",
    "    \n",
    "    def run_gradio(self):\n",
    "\n",
    "        def add_text(history, text):\n",
    "            #print('add_text: history: %s, text: %s'%(history, text))\n",
    "            history = history + [(text, None)]\n",
    "            return history, gr.Textbox(value=\"\", interactive=False)\n",
    "\n",
    "        def add_file(history, file):\n",
    "            #print('add_history: history: %s, file: %s'%(history, file))\n",
    "            history = history + [((file.name,), None)]\n",
    "            return history\n",
    "\n",
    "        def bot(history):\n",
    "            #print('bot: history: %s'%(history))\n",
    "            # prompt to send to the agent is the last message from the user\n",
    "            prompt = history[-1][0]\n",
    "            response = self.query_engine.query(prompt)\n",
    "            print('RESPONSE: %s'%(str(response)))\n",
    "            history[-1][1] = str(response)\n",
    "            print('WHOLE HISTORY: %s'%(history))\n",
    "            return history\n",
    "\n",
    "        with gr.Blocks() as demo:\n",
    "            chatbot = gr.Chatbot(\n",
    "                [],\n",
    "                elem_id=\"chatbot\",\n",
    "                bubble_full_width=False,\n",
    "                #avatar_images=(None, files(alhazen_resources).joinpath('alhazen.png'))\n",
    "            )\n",
    "            with gr.Row():\n",
    "                txt = gr.Textbox(\n",
    "                    scale=4,\n",
    "                    show_label=False,\n",
    "                    placeholder=\"Enter text and press enter, or upload files\",\n",
    "                    container=False,\n",
    "                )\n",
    "                btn = gr.UploadButton(\"üìÅ\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "            txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(bot, chatbot, chatbot)\n",
    "            txt_msg.then(lambda: gr.Textbox(interactive=True), None, [txt], queue=False)\n",
    "            \n",
    "            file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(bot, chatbot, chatbot)\n",
    "\n",
    "        demo.queue()\n",
    "        demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_corpus_chatbot(doc_dir, \n",
    "        llm_name, \n",
    "        embed_model_name=\"BAAI/bge-small-en-v1.5\", \n",
    "        sentence_window_size=3):\n",
    "    \n",
    "    chatbot = FileCollectionChatBot(doc_dir, \n",
    "                llm_name,\n",
    "                embed_model_name=embed_model_name, \n",
    "                sentence_window_size=sentence_window_size)\n",
    "    chatbot.run_gradio()\n",
    "\n",
    "#os.environ['LLMS_TEMP_DIR'] = '/tmp/alhazen'\n",
    "#pdf_corpus_chatbot('/Users/gburns/Documents/2023H2/makeathon/grant_analysis', 'llama-2-70b-chat')\n",
    "\n",
    "#os.environ['OPENAI_API_KEY'] = '<add your key here>'\n",
    "#pdf_corpus_chatbot('/Users/gburns/Documents/2023H2/makeathon/grant_analysis', 'gpt-3.5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alhazen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
