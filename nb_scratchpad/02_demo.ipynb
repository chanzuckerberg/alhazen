{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight demonstration application\n",
    "\n",
    "> Building an application to showcase basic functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gburns/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from alhazen.core import PromptTemplateRegistry, get_langchain_llm, get_langchain_embeddings, GGUF_LOOKUP_URL, MODEL_TYPE\n",
    "import alhazen.utils.jats_text_extractor as te \n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR \n",
    "\n",
    "from importlib_resources import files\n",
    "\n",
    "from langchain.agents import AgentExecutor, load_tools\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import AnalyzeDocumentChain,  RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.prompts import load_prompt, PromptTemplate\n",
    "from langchain.schema.vectorstore import VectorStoreRetriever\n",
    "from langchain.text_splitter import NLTKTextSplitter, CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.tools.render import render_text_description, render_text_description_and_args\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "\n",
    "from langserve import add_routes\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "# We need to add these input/output schemas because the current AgentExecutor\n",
    "# is lacking in schemas.\n",
    "class Input(BaseModel):\n",
    "    input: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: str     \n",
    "\n",
    "class AlhazenDemo:\n",
    "    '''Systems for tool-based agent forming the core of the Alzhazen system.'''\n",
    "\n",
    "    def __init__(self, \n",
    "                home_dir, \n",
    "                model_type=MODEL_TYPE.Ollama,\n",
    "                llm_name='llama2:70b'):\n",
    "        \n",
    "        self.home_dir = home_dir\n",
    "        if home_dir[-1:] != '/':\n",
    "            home_dir += '/'\n",
    "        self.change_directory(self.home_dir)\n",
    "        \n",
    "        self.tools = load_tools([\"ddg-search\", \"pubmed\", \"arxiv\"])\n",
    "\n",
    "        pts = PromptTemplateRegistry()\n",
    "        pts.load_prompts_from_yaml('alhazen_base.yaml')\n",
    "        if model_type == MODEL_TYPE.Ollama:\n",
    "            self.prompt_template = pts.get_prompt_template('alhazen tools').generate_llama2_prompt_template()\n",
    "        else:\n",
    "            self.prompt_template = pts.get_prompt_template('alhazen tools').generate_prompt_template()\n",
    "        self.prompt_template = self.prompt_template.partial(\n",
    "            tools=render_text_description_and_args(self.tools),\n",
    "            tool_names=\", \".join([t.name for t in self.tools]),\n",
    "        )\n",
    "\n",
    "        self.llm = get_langchain_llm(model_type, llm_name)\n",
    "        self.llm_with_stop = self.llm.bind(stop=[\"\\nObservation\"])\n",
    "\n",
    "        self.agent = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "            }\n",
    "            | self.prompt_template\n",
    "            | self.llm_with_stop\n",
    "            | JSONAgentOutputParser()\n",
    "        )\n",
    "\n",
    "        self.agent_executor = AgentExecutor(\n",
    "                agent=self.agent, \n",
    "                tools=self.tools, \n",
    "                verbose=True)\n",
    "        \n",
    "        self.app = self.setup_langserve()\n",
    "\n",
    "    def change_directory(self, doc_dir):\n",
    "        if doc_dir[-1:] != '/':\n",
    "            doc_dir += '/'\n",
    "        file_list = []\n",
    "        dir_list = []\n",
    "        with os.scandir(doc_dir) as it:\n",
    "            for entry in it:\n",
    "                suffix = Path(entry.path).suffix\n",
    "                if entry.is_file():\n",
    "                    if suffix in ['.pdf', '.PDF', '.txt', '.TXT', '.xml', '.XML', '.nxml', '.NXML']:\n",
    "                        file_list.append(entry.name)\n",
    "                elif entry.is_dir():\n",
    "                    dir_list.append(entry.name)\n",
    "        file_list.sort()\n",
    "        dir_list.sort()\n",
    "\n",
    "        # insert '..' into dir_list\n",
    "        dir_list.insert(0, '..')\n",
    "\n",
    "        self.home_dir = doc_dir\n",
    "        self.folder_df = pd.DataFrame(dir_list, columns=['folder'])\n",
    "        self.file_df = pd.DataFrame(file_list, columns=['file'])\n",
    "        return (doc_dir, self.folder_df, self.file_df)\n",
    "\n",
    "    def setup_langserve(self):\n",
    "\n",
    "        app = FastAPI(\n",
    "            title=\"Alhazen Server\",\n",
    "            version=\"0.0.1\",\n",
    "            description=\"An api server using Langchain's Runnable interfaces for Alhazen\",\n",
    "        )\n",
    "\n",
    "        app.add_middleware(\n",
    "            CORSMiddleware,\n",
    "            allow_origins=[\"*\"],\n",
    "            allow_credentials=True,\n",
    "            allow_methods=[\"*\"],\n",
    "            allow_headers=[\"*\"],\n",
    "            expose_headers=[\"*\"],\n",
    "        )\n",
    "\n",
    "        # Adds routes to the app for using the chain under:\n",
    "        # /invoke\n",
    "        # /batch\n",
    "        # /stream\n",
    "        add_routes(app, self.agent_executor.with_types(input_type=Input, output_type=Output))\n",
    "\n",
    "        return app\n",
    "\n",
    "    def run_langserve(self, port=8080):\n",
    "        import uvicorn\n",
    "        uvicorn.run(self.app, host=\"localhost\", port=port)\n",
    "    \n",
    "    def run_gradio(self):\n",
    "\n",
    "        def add_text(history, text):\n",
    "            #print('add_text: history: %s, text: %s'%(history, text))\n",
    "            history = history + [(text, None)]\n",
    "            return history, gr.Textbox(value=\"\", interactive=False)\n",
    "\n",
    "        def select_dir(evt: gr.SelectData):\n",
    "            new_dir = self.home_dir + '/' + evt.value      \n",
    "            if evt.value == '..':\n",
    "                new_dir = str(Path(self.home_dir).parent)\n",
    "            print('select_dir: %s'%(new_dir))\n",
    "            return self.change_directory(new_dir)\n",
    "            \n",
    "        def select_file(evt: gr.SelectData):\n",
    "            file_path = self.home_dir + '/' + evt.value              \n",
    "            return file_path, []\n",
    "            \n",
    "        def clear_chat(history):\n",
    "            return []\n",
    "\n",
    "        def bot(history):\n",
    "            #print('bot: history: %s'%(history))\n",
    "            # prompt to send to the agent is the last message from the user\n",
    "            input = history[-1][0]\n",
    "            response = self.agent_executor.invoke(\n",
    "                {\"input\": input}\n",
    "            )\n",
    "            print('RESPONSE: %s'%(str(response)))\n",
    "            history[-1][1] = str(response.get('result','No answer found'))\n",
    "            print('WHOLE HISTORY: %s'%(history))\n",
    "            return history\n",
    "\n",
    "        with gr.Blocks() as demo:\n",
    "            with gr.Tab(\"Full Text Documents\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        doc_dir = gr.Textbox(show_label=False, lines=1, value=self.home_dir, interactive=False)\n",
    "                        with gr.Row():\n",
    "                            directories = gr.DataFrame(show_label=False, value=self.folder_df, interactive=False)\n",
    "                            files = gr.DataFrame(show_label=False, value=self.file_df, interactive=False)\n",
    "                    doc_text = gr.HTML(label=\"File Contents\")\n",
    "            \n",
    "            with gr.Tab(\"Chat\"):\n",
    "                chatbot = gr.Chatbot(\n",
    "                    [],\n",
    "                    elem_id=\"chatbot\",\n",
    "                    bubble_full_width=False,\n",
    "                    #avatar_images=(None, files(alhazen_resources).joinpath('alhazen.png'))\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    txt = gr.Textbox(\n",
    "                        scale=4,\n",
    "                        show_label=False,\n",
    "                        placeholder=\"Enter text and press enter, or upload files\",\n",
    "                        container=False,\n",
    "                    )\n",
    "                    clear_btn = gr.Button(\"Clear\")\n",
    "\n",
    "            directories.select(select_dir, None, [doc_dir, directories, files], queue=False )   \n",
    "            files.select(select_file, None, [doc_text, chatbot], queue=False )\n",
    "            txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(bot, chatbot, chatbot)\n",
    "            txt_msg.then(lambda: gr.Textbox(interactive=True), None, [txt], queue=False)                \n",
    "            clear_btn.click(clear_chat, [], [chatbot], queue=False)\n",
    "                \n",
    "        demo.queue()\n",
    "        demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [12389]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __          ___      .__   __.   _______      _______. _______ .______     ____    ____  _______ \n",
      "|  |        /   \\     |  \\ |  |  /  _____|    /       ||   ____||   _  \\    \\   \\  /   / |   ____|\n",
      "|  |       /  ^  \\    |   \\|  | |  |  __     |   (----`|  |__   |  |_)  |    \\   \\/   /  |  |__   \n",
      "|  |      /  /_\\  \\   |  . `  | |  | |_ |     \\   \\    |   __|  |      /      \\      /   |   __|  \n",
      "|  `----./  _____  \\  |  |\\   | |  |__| | .----)   |   |  |____ |  |\\  \\----.  \\    /    |  |____ \n",
      "|_______/__/     \\__\\ |__| \\__|  \\______| |_______/    |_______|| _| `._____|   \\__/     |_______|\n",
      "\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/\" is live at:\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  │\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  └──> /playground\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m See all available routes at /docs\n",
      "\n",
      "INFO:     127.0.0.1:65435 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65435 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:65437 - \"GET /playground HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:65437 - \"GET /playground/ HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65437 - \"GET /playground/assets/index-ea49ff70.js HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65438 - \"GET /playground/assets/index-244b2b9b.css HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65437 - \"GET /playground/favicon.ico HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65437 - \"GET /c/N4XyA/input_schema HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [12389]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import uvicorn\n",
    "\n",
    "cb = AlhazenDemo('/Users/gburns/alhazen/em_tech/')\n",
    "config = uvicorn.Config(cb.app)\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alhazen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
