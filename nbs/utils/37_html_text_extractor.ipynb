{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Text Extractor Utility\n",
    "\n",
    "> Extracts unstructured text from scientific papers published as HTML files ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.html_research_article_text_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import dataclasses\n",
    "\n",
    "from typing import Dict, List, Union\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "import re\n",
    "from typing import Optional, List, Iterator, Mapping, Any, Dict\n",
    "from dataclasses import field\n",
    "import requests\n",
    "import nltk\n",
    "import trafilatura as traf\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TrafilaturaSectionLoader(BaseLoader):\n",
    "    \"\"\"Load `HTML` files and parse them with `trafilatura` into sections.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        \"\"\"Initialize with a file path.\"\"\"\n",
    "        try:\n",
    "            import trafilatura as traf\n",
    "            from bs4 import BeautifulSoup\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"trafilatura package not found, please install it with \"\n",
    "                \"`pip install trafilatura`\"\n",
    "            )\n",
    "        self.file_path = file_path\n",
    "        self.bs_kwargs = {\"features\": \"lxml\"}\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load HTML document into document objects.\"\"\"\n",
    "\n",
    "        docs = []        \n",
    "        with open(self.file_path, encoding='utf-8') as f:\n",
    "            j = traf.extract(f.read(), output_format='xml')\n",
    "            soup = BeautifulSoup(j, \"lxml-xml\")\n",
    "            offset = 0\n",
    "            cs = soup.find('head', {'rend': 'h1'})\n",
    "\n",
    "            dt = cs.get_text() + '\\n'\n",
    "            while cs.find_next_sibling() is not None:\n",
    "                cs = cs.find_next_sibling()\n",
    "                dt += cs.get_text() + '\\n'\n",
    "                if cs.name == 'head' and cs.get('rend') == 'h2':\n",
    "                    md = {'c_ids': c_ids, 'e_id': e.id, 'e_type': e.type, 'i_type': 'HTMLFullText', 'offset': offset, 'length': len(dt)}\n",
    "                    docs.append(Document(page_content=dt, metadata=md))\n",
    "                    offset += len(dt)\n",
    "                    dt = cs.get_text() + '\\n'       \n",
    "\n",
    "        return docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
