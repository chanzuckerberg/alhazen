{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tools for Alhazen\n",
    "\n",
    "> Simple tools to demonstrate utility and 'agentic' functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools:\n",
    "1. Develop queries across external data sources\n",
    "2. Execute a query against EPMC, creating a collection and saving expressions, items, and fragments to the database\n",
    "3. Add all available full text to a collection\n",
    "4. Filter a collection by an LLM-based analysis by tagging fragments with Notes\n",
    "5. Extract information from a collection using an LLM-based analysis to create Notes \n",
    "6. Report on the state of the database in terms of numbers of collections, expressions, items, and fragments\n",
    "7. Prepare a report over a core research question by collecting a number of notes and synthesizing them into a report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "![Workflow](https://lucid.app/publicSegments/view/fea24e0a-61c7-4807-8ea2-e4859753c31b/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tools.basic_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from alhazen.utils.airtableUtils import AirtableUtils\n",
    "from alhazen.utils.searchEngineUtils import ESearchQuery, EuroPMCQuery\n",
    "from alhazen.utils.queryTranslator import QueryTranslator, QueryType\n",
    "from alhazen.schema_sqla import ScientificKnowledgeCollection, \\\n",
    "    ScientificKnowledgeExpression, ScientificKnowledgeCollectionHasMembers, \\\n",
    "    ScientificKnowledgeItem, ScientificKnowledgeExpressionHasRepresentation, \\\n",
    "    ScientificKnowledgeFragment, ScientificKnowledgeItemHasPart, \\\n",
    "    InformationResource, Note, NoteIsAbout\n",
    "from alhazen.utils.local_literature_db import QuerySpec, LocalLiteratureDb\n",
    "from alhazen.utils.jats_text_extractor import NxmlDoc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine, exists, func\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EMPCSearchToolSchema(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "    name: str = Field(description=\"should be the name of the collection we will add papers to\")\n",
    "\n",
    "class EMPCSearchTool(BaseTool):\n",
    "    name = \"epmc_search\"\n",
    "    description = \"useful for when you need to search for biomedical scientific papers\"\n",
    "    args_schema: Type[EMPCSearchToolSchema] = EMPCSearchToolSchema\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        name: str,\n",
    "        query: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        if os.environ.get('LLMS_TEMP_DIR') is None: \n",
    "            raise Exception('Where are you storing your local literature database?')\n",
    "        loc = os.environ['LLMS_TEMP_DIR']\n",
    "        if os.environ.get('DB_NAME') is None: \n",
    "            raise Exception('Which database do you want to use for this application?')\n",
    "        db_name = os.environ['DB_NAME']\n",
    "        db = LocalLiteratureDb(loc, db_name)\n",
    "        if db.session is None:\n",
    "            session_class = sessionmaker(bind=db.engine)\n",
    "            db.session = session_class()\n",
    "\n",
    "        r = db.session.query(func.max(ScientificKnowledgeCollection.id)).first()\n",
    "        max_id = r[0]\n",
    "        if max_id is None:\n",
    "            c_id = 0\n",
    "        else:\n",
    "            c_id = int(max_id) + 1\n",
    "\n",
    "        cdf = pd.DataFrame([{'ID': c_id, 'NAME': name, 'QUERY': query}])        \n",
    "        qs = QuerySpec(db_name, 'ID', 'QUERY', 'NAME', {}, ['TITLE','ABSTRACT'])\n",
    "        qt = QueryTranslator(cdf.sort_values('ID'), 'ID', 'QUERY', 'NAME')\n",
    "        \n",
    "        db.add_corpus_from_epmc(qt, None, sections=qs.sections)\n",
    "\n",
    "        r2 = db.session.query(func.count(ScientificKnowledgeExpression.id)) \\\n",
    "                .filter(ScientificKnowledgeCollection.id == ScientificKnowledgeCollectionHasMembers.ScientificKnowledgeCollection_id) \\\n",
    "                .filter(ScientificKnowledgeCollectionHasMembers.has_members_id == ScientificKnowledgeExpression.id) \\\n",
    "                .filter(ScientificKnowledgeCollection.id == c_id).first()\n",
    "        n_papers_added = r2[0]\n",
    "\n",
    "        r2 = db.session.query(func.count(ScientificKnowledgeExpression.id)) \\\n",
    "                .filter(ScientificKnowledgeCollection.id == ScientificKnowledgeCollectionHasMembers.ScientificKnowledgeCollection_id) \\\n",
    "                .filter(ScientificKnowledgeCollectionHasMembers.has_members_id == ScientificKnowledgeExpression.id) \\\n",
    "                .filter(ScientificKnowledgeCollection.id == c_id).first()\n",
    "        n_papers_added = r2[0]\n",
    "\n",
    "        return {'action': 'Final Answer', \n",
    "                'action_input': 'Successfully constructed a collection called `{}` containing {} papers by querying EMPC'.format(name, n_papers_added)}\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        name: str,\n",
    "        query: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"epmc_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2816.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1440.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ebi.ac.uk/europepmc/webservices/rest/search?format=JSON&pageSize=1000&synonym=TRUE&resultType=core&query=((TITLE:\"Cryoelectron Tomography\" OR ABSTRACT:\"Cryoelectron Tomography\") OR (TITLE:\"Cryo Electron Tomography\" OR ABSTRACT:\"Cryo Electron Tomography\") OR (TITLE:\"Cryo-Electron Tomography\" OR ABSTRACT:\"Cryo-Electron Tomography\") OR (TITLE:\"Cryo-ET\" OR ABSTRACT:\"Cryo-ET\") OR (TITLE:\"CryoE\" OR ABSTRACT:\"CryoE\")), 1847 European PMC PAPERS FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:31<00:00, 15.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Returning 1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1847/1847 [00:06<00:00, 305.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'Final Answer',\n",
       " 'action_input': 'Successfully constructed a collection called More Stuff4 containing 1847 papers from EPMC'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LLMS_TEMP_DIR'] = '/tmp/alhazen/'\n",
    "os.environ['DB_NAME'] = 'temp'\n",
    "\n",
    "t = EMPCSearchTool()\n",
    "t._run(name='More Stuff4', query='Cryoelectron Tomography | Cryo Electron Tomography | Cryo-Electron Tomography | Cryo-ET | CryoE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alhazen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
