{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama2 LangChain Output Parsers  \n",
    "\n",
    " > Fixing common errors from Llama2 outputs that do not conform to standards set by OpenAI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.output_parsers\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "\n",
    "import json\n",
    "\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models.ollama import ChatOllama\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage, AIMessage\n",
    "from langchain.schema import BaseMessage, BaseOutputParser, OutputParserException\n",
    "from langchain.schema import LLMResult\n",
    "from langchain.utils.input import print_text\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from typing import (\n",
    "    Any,\n",
    "    Dict,\n",
    "    List,\n",
    "    Union,\n",
    "    Optional\n",
    ")\n",
    "\n",
    "import json\n",
    "import re\n",
    "from typing import Union\n",
    "\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain.agents.chat.prompt import FORMAT_INSTRUCTIONS\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "from langchain.output_parsers.json import parse_json_markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseOutputParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gburns/Documents/Coding/ChatGPT_etc/alzhazen/nbs/30_general_langchain_utils.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gburns/Documents/Coding/ChatGPT_etc/alzhazen/nbs/30_general_langchain_utils.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#| export\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gburns/Documents/Coding/ChatGPT_etc/alzhazen/nbs/30_general_langchain_utils.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mJsonEnclosedByTextOutputParser\u001b[39;00m(BaseOutputParser[Any]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gburns/Documents/Coding/ChatGPT_etc/alzhazen/nbs/30_general_langchain_utils.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse the output of an LLM call to a JSON object.\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gburns/Documents/Coding/ChatGPT_etc/alzhazen/nbs/30_general_langchain_utils.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseOutputParser' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "class JsonEnclosedByTextOutputParser(BaseOutputParser[Any]):\n",
    "    \"\"\"Parse the output of an LLM call to a JSON object.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> Any:\n",
    "        text = text.strip()\n",
    "        m = re.search('.*([\\[\\{](.|\\n)*[\\}\\]]).*', text, flags=re.M)\n",
    "        if m:\n",
    "            text1 = m.group(1)\n",
    "\n",
    "            # need to make sure all entries in the JSON are quoted\n",
    "            # so that the JSON parser can parse it\n",
    "            # e.g. {\"a\": E} -> {\"a\": \"E\"}\n",
    "            # this is a hack, but it works\n",
    "            text2 = re.sub(r':\\s*([a-zA-Z0-9_]+)\\s*([,\\]\\}])', r': \"\\1\"\\2', text1)\n",
    "            try:\n",
    "                return json.loads(text2)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise OutputParserException(f\"Invalid json output: {text2} derived from {text}\") from e\n",
    "        else: \n",
    "            raise OutputParserException(f\"Could not find json-formatted data in: {text}\")\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"json_enclosed_by_text_output_parser\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "FINAL_ANSWER_ACTION = \"Final Answer:\"\n",
    "\n",
    "class ReActJsonSingleInputOutputParser_llama2(AgentOutputParser):\n",
    "    \"\"\"Parses ReAct-style LLM calls that have a single tool input in json format.\n",
    "\n",
    "    Expects output to be in one of two formats.\n",
    "\n",
    "    If the output signals that an action should be taken,\n",
    "    should be in the below format. This will result in an AgentAction\n",
    "    being returned.\n",
    "\n",
    "    ```\n",
    "    Thought: agent thought here\n",
    "    Action:\n",
    "    ```\n",
    "    {\n",
    "        \"action\": \"search\",\n",
    "        \"action_input\": \"what is the temperature in SF\"\n",
    "    }\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "    If the output signals that a final answer should be given,\n",
    "    should be in the below format. This will result in an AgentFinish\n",
    "    being returned.\n",
    "\n",
    "    ```\n",
    "    Thought: agent thought here\n",
    "    Final Answer: The temperature is 100 degrees\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #pattern = re.compile(r\"^.*?`{3}(?:json)?\\n(.*?)`{3}.*?$\", re.DOTALL)\n",
    "    pattern = re.compile('.*([\\[\\{].*[\\}\\]]).*', re.DOTALL)\n",
    "    \"\"\"Regex pattern to parse the output.\"\"\"\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return FORMAT_INSTRUCTIONS\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        includes_answer = FINAL_ANSWER_ACTION in text\n",
    "        try:\n",
    "            found = self.pattern.search(text)\n",
    "            if not found:\n",
    "                # Fast fail to parse Final Answer.\n",
    "                raise ValueError(\"action not found\")\n",
    "            action = found.group(1)\n",
    "            action_clean = re.sub(r':\\s*([a-zA-Z0-9_]+)\\s*([,\\]\\}])', r': \"\\1\"\\2', action)\n",
    "            response = json.loads(action_clean.strip())\n",
    "            includes_action = \"action\" in response\n",
    "            if includes_answer and includes_action:\n",
    "                raise OutputParserException(\n",
    "                    \"Parsing LLM output produced a final answer \"\n",
    "                    f\"and a parse-able action: {text}\"\n",
    "                )\n",
    "            return AgentAction(\n",
    "                response[\"action\"], response.get(\"action_input\", {}), text\n",
    "            )\n",
    "\n",
    "        except Exception:\n",
    "            if not includes_answer:\n",
    "                raise OutputParserException(f\"Could not parse LLM output: {text}\")\n",
    "            output = text.split(FINAL_ANSWER_ACTION)[-1].strip()\n",
    "            return AgentFinish({\"output\": output}, text)\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"react-json-single-input\"\n",
    "\n",
    "class JSONAgentOutputParser_llama2(AgentOutputParser):\n",
    "    \"\"\"Parses tool invocations and final answers in JSON format.\n",
    "\n",
    "    Expects output to be in one of two formats.\n",
    "\n",
    "    If the output signals that an action should be taken,\n",
    "    should be in the below format. This will result in an AgentAction\n",
    "    being returned.\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"action\": \"search\",\n",
    "      \"action_input\": \"2+2\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    If the output signals that a final answer should be given,\n",
    "    should be in the below format. This will result in an AgentFinish\n",
    "    being returned.\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"action\": \"Final Answer\",\n",
    "      \"action_input\": \"4\"\n",
    "    }\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        try:\n",
    "            response = parse_json_markdown(text)\n",
    "            if isinstance(response, list):\n",
    "                # gpt turbo frequently ignores the directive to emit a single action\n",
    "                logger.warning(\"Got multiple action responses: %s\", response)\n",
    "                response = response[0]\n",
    "            if response[\"action\"] == \"Final Answer\":\n",
    "                return AgentFinish({\"output\": response[\"action_input\"]}, text)\n",
    "            else:\n",
    "                return AgentAction(\n",
    "                    response[\"action\"], response.get(\"action_input\", {}), text\n",
    "                )\n",
    "        except Exception as e:\n",
    "            raise OutputParserException(f\"Could not parse LLM output: {text}\") from e\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"json-agent\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
