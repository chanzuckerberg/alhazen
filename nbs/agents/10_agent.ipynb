{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Alhazen Agent / Chatbot.\n",
    "\n",
    "> Building a simple Gradio application to allow the user to chat to Alhazen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gully.burns/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "from alhazen.core import PromptTemplateRegistry, load_alhazen_tool_environment\n",
    "from alhazen.schema_sqla import *\n",
    "from alhazen.tools.basic import IntrospectionTool\n",
    "from alhazen.tools.paperqa_emulation_tool import PaperQAEmulationTool\n",
    "from alhazen.tools.metadata_extraction_tool import * \n",
    "from alhazen.toolkit import AlhazenToolkit\n",
    "from alhazen.utils.jats_text_extractor import NxmlDoc\n",
    "from alhazen.utils.ceifns_db import Ceifns_LiteratureDb, create_ceifns_database, drop_ceifns_database\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent, AgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import ReActJsonSingleInputOutputParser\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "from langchain.output_parsers.json import parse_json_markdown\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.tools.render import render_text_description, render_text_description_and_args\n",
    "from langchain.agents.output_parsers.json import JSONAgentOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Sequence, Union, Any\n",
    "from uuid import UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class AlhazenAgent:\n",
    "    '''The base Alhazen agent.'''\n",
    "\n",
    "    def __init__(self, agent_llm, tool_llm, db_name, sml=None, verbose=True, return_intermediate_steps=True):\n",
    "\n",
    "        loc = load_alhazen_tool_environment()\n",
    "\n",
    "        self.db = Ceifns_LiteratureDb(loc=loc, name=db_name)\n",
    "        self.agent_llm  = agent_llm\n",
    "        self.tool_llm  = tool_llm\n",
    "\n",
    "        self.tk = AlhazenToolkit(db=self.db, llm=self.tool_llm)\n",
    "        self.tools = self.tk.get_tools()\n",
    "\n",
    "        pts = PromptTemplateRegistry()\n",
    "        pts.load_prompts_from_yaml('alhazen_base.yaml')\n",
    "\n",
    "        self.prompt = pts.get_prompt_template('structured chat agent').generate_chat_prompt_template()\n",
    "        \n",
    "        agent = create_structured_chat_agent_withFixes(self.agent_llm, self.tools, self.prompt)\n",
    " \n",
    "        self.agent_executor = AgentExecutor(agent=agent, \n",
    "                                            tools=self.tools,\n",
    "                                            verbose=verbose, \n",
    "                                            return_intermediate_steps=return_intermediate_steps)\n",
    "\n",
    "def create_structured_chat_agent_withFixes(\n",
    "    llm: BaseLanguageModel, tools: Sequence[BaseTool], prompt: ChatPromptTemplate\n",
    ") -> Runnable:\n",
    "    \"\"\"modified from `create_structured_chat_agent` to deal with escaped underscore characters.\"\"\"\n",
    "\n",
    "    missing_vars = {\"tools\", \"tool_names\", \"agent_scratchpad\"}.difference(\n",
    "        prompt.input_variables\n",
    "    )\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Prompt missing required variables: {missing_vars}\")\n",
    "\n",
    "    prompt = prompt.partial(\n",
    "        tools=render_text_description_and_args(list(tools)),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "    )\n",
    "    llm_with_stop = llm.bind(stop=[\"Observation\"])\n",
    "\n",
    "    agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        )\n",
    "        | prompt\n",
    "        | llm_with_stop\n",
    "        | JSONAgentOutputParser_withFixes()\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "class JSONAgentOutputParser_withFixes(AgentOutputParser):\n",
    "    \"\"\"modified from `JSONAgentOutputParser` to deal with escaped underscore characters.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        try:\n",
    "            text = text.strip()\n",
    "\n",
    "            # Hack to remove escaped underscores.\n",
    "            text = re.sub('\\\\\\\\_', '_', text)\n",
    "            text = re.sub('\\\\\\\\_', '_', text)\n",
    "\n",
    "            # Hack to look for the JSON code fragment \n",
    "            # inside other text inside the \n",
    "            m = re.search('.*?([\\[\\{](.|\\n)*[\\}\\]]).*?', text, flags=re.M)\n",
    "            if m:\n",
    "                text = m.group(1)\n",
    "\n",
    "            response = parse_json_markdown(text)\n",
    "            if isinstance(response, list):\n",
    "                # gpt turbo frequently ignores the directive to emit a single action\n",
    "                response = response[0]\n",
    "            if response[\"action\"] == \"Final Answer\":\n",
    "                return AgentFinish({\"output\": response[\"action_input\"]}, text)\n",
    "            else:\n",
    "                return AgentAction(\n",
    "                    response[\"action\"], response.get(\"action_input\", {}), text\n",
    "                )\n",
    "        except Exception as e:\n",
    "            raise OutputParserException(f\"Could not parse LLM output: {text}\") from e\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"json-agent\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alhazen",
   "language": "python",
   "name": "alhazen"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
