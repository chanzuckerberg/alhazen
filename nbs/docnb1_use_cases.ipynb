{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# THIS IS A DOCUMENTATION ONLY NOTEBOOK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cases\n",
    "\n",
    "> What is Alhazen designed to do? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZI's Mission - Build, Fund, Do\n",
    "\n",
    "Broadly, [our scientific mission](https://chanzuckerberg.com/science/) at the Chan Zuckerberg Initiative (CZI) is expressed as: \n",
    "\n",
    ">We __build__ open source software tools to accelerate science and generate more accurate and biologically important sources of data. We __fund__ scientific research worldwide to advance the frontiers of knowledge. And we launched a family of institutes to __do__ research that canâ€™t be done in conventional environments. Each aspect is essential to our approach to building for the long term. \n",
    "\n",
    "We describe this coordinated activity as '__Build__ / __Fund__ / __Do__', so that our SciTech development work (the '__Build__' compontent), is based on scientific challenges and use cases provided by the collaborative research networks that funding supports ('__Fund__') and direct research activities undertaken within the CZI research organizations such as the CZI BioHubs and the Chan Zuckerberg Imaging Institute ('__Do__'). In particular, our scientific work generates complex research landscaping requirements that we seek to address using the latest available AI technology. \n",
    "\n",
    "# Alhazen - Basic Functionality and Design Choices\n",
    "\n",
    "The __Alhazen__ system is intended to provide open-source infrastructure that supports landscape analysis of scientific knowledge (from both the literature and other online sources) using large language model technology including LLM-enabled workflows and automated agent-based tool use (provided by [the LangChain library](https://www.langchain.com/)).    \n",
    "\n",
    "* We prioritize the use of open source Large Language Models (but support access to state-of-the-art commercial systems like )\n",
    "* Explore the competitive utility of being able to execute long-running processing chains on local GPUs that would otherwise be prohibitively expensive for commercial systems. \n",
    "* Emulate the working process of a diligent, hard-working scientist who rigorously reads documents in depth, makes notes, and then bases their conclusions on summaries of their notes with full explanations of how they got there. This is juxtaposed to QA systems designed to answer questions quickly based on lightweight indexes of source material.\n",
    "* Use LangChain as the core library for this work. \n",
    "\n",
    "At present, these constitute works-in-progress that utilize elements of the Alhazen system expressed as Jupyter Notebooks in the [`nb/cookbook`](https://github.com/chanzuckerberg/alhazen/tree/main/nbs/cookbook) subdirectory.\n",
    "\n",
    "# Scientific Use Cases \n",
    "\n",
    "These use cases include:\n",
    "\n",
    "1. Zero-shot information extraction of metadata from the methods sections of full text papers describing CryoET papers in order to support curation of that data into the [CZI CryoET Portal](https://chanzuckerberg.github.io/cryoet-data-portal/) system - see below.   \n",
    "2. Understanding distribution of types of experimental studies in rare disease research (see [Human Annotated Corpus for Disease Research State Classifications](https://github.com/chanzuckerberg/DRSM-corpus))\n",
    "3. Landscaping analysis of researchers working on Infectious Disease in Low-Middle Income Countries (LMIC)\n",
    "4. Zero-shot extractions of the names of advanced imaging methods from methods papers in a small subset of journals.  \n",
    "5. Searches for key opinion leaders from Africa working in the field of microscopy \n",
    "\n",
    "## Key Use Case: Metadata Extraction for Curation of Data into a Repository\n",
    "\n",
    "A key use case for this effort is the development of tools that can assist curation of complex datasets to a central repository (such as for the Chan Zuckerberg Imaging Institute's [CryoET Data Portal](https://chanzuckerberg.github.io/cryoet-data-portal/).  \n",
    "\n",
    "We currently seek to improve this use case by including ontology search / matching capabilities to the extracted text and to generalize the extraction process to other protocol types. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
