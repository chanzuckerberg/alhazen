{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods Metadata Extraction Tool   \n",
    "\n",
    "> Langchain tools that execute zero-shot extraction over a local database of full text papers previously imported into our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tools.metadata_extraction_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from alhazen.aliases import *\n",
    "from alhazen.core import PromptTemplateRegistry\n",
    "from alhazen.tools.basic import AlhazenToolMixin\n",
    "from alhazen.utils.output_parsers import JsonEnclosedByTextOutputParser\n",
    "from alhazen.utils.ceifns_db import *\n",
    "from alhazen.schema_sqla import *\n",
    "from datetime import datetime\n",
    "from importlib_resources import files\n",
    "import jmespath\n",
    "import json\n",
    "\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, root_validator\n",
    "from langchain.schema import get_buffer_string, StrOutputParser, OutputParserException, format_document\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain.tools import BaseTool, StructuredTool\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "\n",
    "import local_resources.prompt_elements as prompt_elements\n",
    "import local_resources.linkml as linkml\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import regex\n",
    "from sqlalchemy import create_engine, exists\n",
    "from sqlalchemy.orm import sessionmaker, aliased\n",
    "from time import time,sleep\n",
    "import tiktoken\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus, quote, unquote\n",
    "import uuid\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| export\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMetadataExtractionToolSchema\u001b[39;00m(\u001b[43mBaseModel\u001b[49m):\n\u001b[1;32m      4\u001b[0m     paper_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe doi of the paper being analyzed, must start with the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoi:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     extraction_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the name of the type of extraction and must be one of the following strings: [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcryoet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseModel' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "class MetadataExtractionToolSchema(BaseModel):\n",
    "    paper_id: str = Field(description=\"the doi of the paper being analyzed, must start with the string 'doi:'\")\n",
    "    extraction_type: str = Field(description=\"This is the name of the type of extraction and must be one of the following strings: ['cryoet']\")\n",
    "    run_label: Optional[str] = Field(description=\"This is a label that will be used to identify the run of the metadata extraction tool in the database.\")\n",
    "\n",
    "class BaseMetadataExtractionTool(BaseTool, AlhazenToolMixin):\n",
    "    '''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\n",
    "    name = 'metadata_extraction'\n",
    "    description = 'Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'\n",
    "    args_schema = MetadataExtractionToolSchema\n",
    "    return_direct:bool = True\n",
    "    examples = {}\n",
    "\n",
    "    def _run(self, paper_id, extraction_type):\n",
    "        '''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\n",
    "        raise NotImplementedError('This method must be implemented by a subclass.')\n",
    "    \n",
    "    def compile_answers(self, spec, data_file_path):\n",
    "        '''Compiles the answers to the metadata extraction questions into a single JSON object.'''\n",
    "        \n",
    "        pts = PromptTemplateRegistry()\n",
    "        pts.load_prompts_from_yaml('metadata_extraction.yaml')\n",
    "        prompt_elements_yaml = files(prompt_elements).joinpath('metadata_extraction.yaml').read_text()\n",
    "        prompt_elements_dict = yaml.safe_load(prompt_elements_yaml).get(spec)\n",
    "        metadata_specs = prompt_elements_dict.get('metadata specs',[])\n",
    "        dataset_publication_path = prompt_elements_dict['dataset_publication_path']\n",
    "        \n",
    "        # walk over the directory tree underneath data_file_path\n",
    "        # and compile the answers to the metadata extraction questions\n",
    "        # for each file in the directory tree\n",
    "        yaml_files = []\n",
    "        tsv_files = []\n",
    "        for root, dirs, file_list in os.walk(data_file_path):\n",
    "            for file in file_list:\n",
    "                if file.endswith(\".yaml\"):\n",
    "                    yaml_files.append((root, file))\n",
    "                if file.endswith(\".tsv\"):\n",
    "                    tsv_files.append((root, file))\n",
    "\n",
    "        self.examples = {} \n",
    "        for root, file in yaml_files:\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                d = yaml.safe_load(f)\n",
    "                for q in metadata_specs:\n",
    "                    path = q.get('path')\n",
    "                    dois = jmespath.search(dataset_publication_path, d).split(',')             \n",
    "                    answer = jmespath.search(path, d)\n",
    "                    if answer is None:\n",
    "                        answer = []\n",
    "                    else:\n",
    "                        if not isinstance(answer, list):\n",
    "                            answer = [answer]\n",
    "                        else:\n",
    "                            answer = list(set(answer))\n",
    "                    for doi in dois:\n",
    "                        if doi[0:4] != 'doi:' or len(answer) == 0:\n",
    "                            continue\n",
    "                        self.examples[q.get('name')][doi.strip()] = list(set(answer))\n",
    "\n",
    "        for root, file in tsv_files:\n",
    "            df = pd.read_csv(os.path.join(root, file), sep='\\t')\n",
    "            for i, row in df.iterrows():\n",
    "                doi = row.doi\n",
    "                if doi[0:4] != 'doi:':\n",
    "                    doi = 'doi:'+doi\n",
    "                for q in metadata_specs:\n",
    "                    if self.examples.get(q.get('name'), None) is None:\n",
    "                        self.examples[q.get('name')] = {}\n",
    "                    if doi not in self.examples.get(q.get('name'), []):\n",
    "                        self.examples[q.get('name')][doi] = []\n",
    "                    if q.get('name') in list(row.keys()):\n",
    "                        v = str(row[str(q.get('name'))])\n",
    "                        if v == v and v != 'nan':\n",
    "                            self.examples[q.get('name')][doi].append(str(row[str(q.get('name'))]))\n",
    "        \n",
    "        for q in self.examples:\n",
    "            for doi in self.examples[q]:\n",
    "                self.examples[q][doi] = ', '.join(sorted(set(self.examples[q][doi])))\n",
    "\n",
    "    def write_answers_as_notes(self, extraction_type, data_file_path): \n",
    "        dois = sorted(list(set([doi for q in self.examples for doi in self.examples[q]])))\n",
    "        for doi in dois:\n",
    "            ske = self.db.session.query(SKE) \\\n",
    "                .filter(SKE.id == doi).first() \n",
    "            if ske is None:\n",
    "                continue\n",
    "            content = {q:self.examples[q].get(doi) for q in self.examples}\n",
    "            n = Note(\n",
    "                id=uuid.uuid4().hex[0:10],\n",
    "                type='MetadataExtractionNote', \n",
    "                name = extraction_type+'__'+doi+'__gold',\n",
    "                provenance='gold standard data loaded from '+data_file_path,\n",
    "                content=json.dumps(content, indent=4), \n",
    "                creation_date=datetime.now(), \n",
    "                format='json')\n",
    "            n.is_about.append(ske)\n",
    "            self.db.session.add(n)\n",
    "            self.db.session.flush()\n",
    "        self.db.session.commit()\n",
    "\n",
    "    def read_metadata_extraction_notes(self, paper_id, extraction_type, run_label = 'test'):    \n",
    "        l = []\n",
    "        q = self.db.session.query(N) \\\n",
    "            .filter(N.id == NIA.Note_id) \\\n",
    "            .filter(NIA.is_about_id == paper_id) \\\n",
    "            .filter(N.type == 'MetadataExtractionNote') \\\n",
    "            .filter(N.name.like(extraction_type+'_%_'+run_label)) \n",
    "\n",
    "        for n in q.all():\n",
    "            tup = json.loads(n.content)\n",
    "            tup['doi'] = paper_id\n",
    "            tup['extraction_type'] = extraction_type\n",
    "            tup['run_label'] = run_label\n",
    "            #deets = json.loads(n.provenance)\n",
    "            #tup['tool_name'] = deets.get('tool')\n",
    "            #tup['llm_name'] = deets.get('llm_class')\n",
    "            #tup['llm_desc'] = deets.get('llm_desc')  \n",
    "            #tup['variable'] = deets.get('variable')\n",
    "            l.append(tup)\n",
    "\n",
    "        return l \n",
    "\n",
    "    def report_metadata_extraction_for_collection(self, collection_id, extraction_type, run_label = 'test'):    \n",
    "        l = []\n",
    "        q = self.db.session.query(N,SKE) \\\n",
    "            .filter(N.id == NIA.Note_id) \\\n",
    "            .filter(NIA.is_about_id == SKE.id) \\\n",
    "            .filter(SKC_HM.has_members_id == SKE.id) \\\n",
    "            .filter(SKC_HM.ScientificKnowledgeCollection_id == collection_id) \\\n",
    "            .filter(N.type == 'MetadataExtractionNote') \\\n",
    "            .filter(N.name.like(extraction_type+'_%_'+run_label)) \n",
    "\n",
    "        for n, ske in q.all():\n",
    "            tup = json.loads(n.content)\n",
    "            tup['doi'] = ske.id\n",
    "            tup['reference'] = ske.content\n",
    "            tup['extraction_type'] = extraction_type\n",
    "            tup['run_label'] = run_label\n",
    "            #deets = json.loads(n.provenance)\n",
    "            #tup['tool_name'] = deets.get('tool')\n",
    "            #tup['llm_name'] = deets.get('llm_class')\n",
    "            #tup['llm_desc'] = deets.get('llm_desc')  \n",
    "            #tup['variable'] = deets.get('variable')\n",
    "            l.append(tup)\n",
    "        \n",
    "        df = pd.DataFrame(l)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseMetadataExtractionTool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| export\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMetadataExtraction_EverythingEverywhere_Tool\u001b[39;00m(\u001b[43mBaseMetadataExtractionTool\u001b[49m):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata_extraction\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseMetadataExtractionTool' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "class MetadataExtraction_EverythingEverywhere_Tool(BaseMetadataExtractionTool):\n",
    "    '''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\n",
    "    name = 'metadata_extraction'\n",
    "    description = 'Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'\n",
    "\n",
    "    def _run(self, paper_id, extraction_type, run_label='test'):\n",
    "        '''Runs the metadata extraction pipeline over a specified paper.'''\n",
    "\n",
    "        if self.db.session is None:\n",
    "            session_class = sessionmaker(bind=self.db.engine)\n",
    "            self.db.session = session_class()\n",
    "\n",
    "        ske = self.db.session.query(SKE) \\\n",
    "                .filter(SKE.id.like('%'+paper_id+'%')).first()    \n",
    "\n",
    "        # Introspect the class name of the llm model for notes and logging\n",
    "        llm_class_name = self.llm.__class__.__name__\n",
    "\n",
    "        run_metadata = {\n",
    "            'tool': self.__class__.__name__,\n",
    "            'extraction_type': extraction_type,\n",
    "            'doi': paper_id,\n",
    "            'llm_class': llm_class_name}\n",
    "\n",
    "        # 0. Use the first available full text item type\n",
    "        item_types = set()\n",
    "        item_type = None\n",
    "        for i in self.db.list_items_for_expression(paper_id):\n",
    "            item_types.add(i.type)\n",
    "        for i_type in item_types:\n",
    "            if i_type == 'CitationRecord':\n",
    "                continue\n",
    "            item_type = i_type\n",
    "            break\n",
    "        if item_type is None:\n",
    "            return {'answer': \"Could not retrieve full text of the paper: %s.\"%(paper_id),\n",
    "                \"data\": {'list_of_answers': None, 'run': run_metadata} }\n",
    "\n",
    "        # 1. Build LangChain elements\n",
    "        pts = PromptTemplateRegistry()\n",
    "        \n",
    "        pts.load_prompts_from_yaml('metadata_extraction.yaml')\n",
    "        prompt_elements_yaml = files(prompt_elements).joinpath('metadata_extraction.yaml').read_text()\n",
    "        prompt_elements_dict = yaml.safe_load(prompt_elements_yaml).get(extraction_type)\n",
    "        method_goal = prompt_elements_dict['method goal']\n",
    "        methodology = prompt_elements_dict['methodology']\n",
    "        metadata_specs = prompt_elements_dict.get('metadata specs',[])\n",
    "        metadata_extraction_prompt_template = pts.get_prompt_template('metadata extraction (all questions, whole paper)').generate_chat_prompt_template()\n",
    "        extract_lcel = metadata_extraction_prompt_template | self.llm | JsonEnclosedByTextOutputParser()\n",
    "        \n",
    "        # 2. Run through all available sections of the paper and identify only those that are predominantly methods sections.\n",
    "        start = datetime.now()\n",
    "        text = '\\n\\n'.join([f.content for f in self.db.list_fragments_for_paper(paper_id, item_type, fragment_types=['section'])])\n",
    "\n",
    "        if len(text) == 0:\n",
    "            return {'answer': \"Could not retrieve full text of the paper: %s.\"%(paper_id),\n",
    "                \"data\": {'list_of_answers': None, 'run': run_metadata} }\n",
    "\n",
    "        # 3. Compile the extraction questions\n",
    "        question_text_list = [(\"%d. %s Record this value in the '%s' field of the output.\")\n",
    "                                %(i+1, spec.get('spec'), spec.get('name')) \n",
    "                                for i, spec in enumerate(metadata_specs)]\n",
    "        questions_output_specification = '\\n'.join(question_text_list)\n",
    "        questions_output_specification += '\\nGenerate only JSON formatted output with %d fields:\\n'%(len(metadata_specs))\n",
    "        questions_output_specification += \", \".join([spec.get('name') for spec in metadata_specs])\n",
    "\n",
    "        # 4. Assemble chain input\n",
    "        s1 = {'section_text': text,\n",
    "                'methodology': methodology,\n",
    "                'method_goal': method_goal,\n",
    "                'questions_output_specification': questions_output_specification}\n",
    "        \n",
    "        # 5. Run the chain with a JsonEnclosedByTextOutputParser \n",
    "        output = None\n",
    "        attempts = 0\n",
    "        full_answer = []\n",
    "        output = extract_lcel.invoke(s1, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "        total_execution_time = datetime.now() - start\n",
    "        time_per_variable = total_execution_time / len(metadata_specs)\n",
    "\n",
    "        if output is None:\n",
    "            return {'answer': \"attempted and failed metadata extraction for an experiment of type '%s' from %s.\"%(methodology, paper_id),\n",
    "                \"data\": {'list_of_answers': None, 'run': run_metadata} }\n",
    "        \n",
    "        run_metadata['timestamp'] = start.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        run_metadata['time_taken'] = str(total_execution_time)\n",
    "        run_name = extraction_type+'__'+paper_id+'__'+run_label\n",
    "        n = Note(\n",
    "            id=uuid.uuid4().hex[0:10],\n",
    "            type='MetadataExtractionNote', \n",
    "            name=run_name,\n",
    "            provenance=json.dumps(run_metadata, indent=4),\n",
    "            content=json.dumps(output, indent=4), \n",
    "            creation_date=datetime.now(), \n",
    "            format='json')\n",
    "\n",
    "        n.is_about.append(ske)\n",
    "        self.db.session.add(n)\n",
    "        self.db.session.flush()\n",
    "                    \n",
    "        # commit the changes to the database\n",
    "        self.db.session.commit()\n",
    "        \n",
    "        return {'answer': \"completed metadata extraction for an experiment of type '%s' from %s.\"%(methodology, paper_id),\n",
    "                \"data\": output, \n",
    "                'run': run_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MetadataExtraction_MethodsSectionOnly_Tool(BaseMetadataExtractionTool):\n",
    "    '''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\n",
    "    name = 'metadata_extraction'\n",
    "    description = 'Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'\n",
    "\n",
    "    def _run(self, paper_id, extraction_type, run_label='test'):\n",
    "        '''Runs the metadata extraction pipeline over a specified paper.'''\n",
    "\n",
    "        if self.db.session is None:\n",
    "            session_class = sessionmaker(bind=self.db.engine)\n",
    "            self.db.session = session_class()\n",
    "\n",
    "        ske = self.db.session.query(SKE) \\\n",
    "                .filter(SKE.id.like('%'+paper_id+'%')).first()    \n",
    "\n",
    "        # Introspect the class name of the llm model for notes and logging\n",
    "        llm_class_name = self.llm.__class__.__name__\n",
    "\n",
    "        run_metadata = {\n",
    "            'tool': self.__class__.__name__,\n",
    "            'doi': paper_id,\n",
    "            'llm_class': llm_class_name}\n",
    "\n",
    "        # 0. Use the first available full text item type\n",
    "        item_types = set()\n",
    "        item_type = None\n",
    "        for i in self.db.list_items_for_expression(paper_id):\n",
    "            item_types.add(i.type)\n",
    "        for i_type in item_types:\n",
    "            if i_type == 'CitationRecord':\n",
    "                continue\n",
    "            item_type = i_type\n",
    "            break\n",
    "        if item_type is None:\n",
    "            return {'answer': \"Could not retrieve full text of the paper: %s.\"%(paper_id),\n",
    "                \"data\": {'list_of_answers': None, 'run': run_metadata} }\n",
    "\n",
    "        # 1. Build LangChain elements\n",
    "        pts = PromptTemplateRegistry()\n",
    "        \n",
    "        #pts.load_prompts_from_yaml('document_structure.yaml')\n",
    "        #section_classifier_prompt_template = pts.get_prompt_template('full text paper section classification').generate_chat_prompt_template()\n",
    "        #section_classifier_lcel = section_classifier_prompt_template | self.slm | JsonEnclosedByTextOutputParser()\n",
    "\n",
    "        pts.load_prompts_from_yaml('metadata_extraction.yaml')\n",
    "        prompt_elements_yaml = files(prompt_elements).joinpath('metadata_extraction.yaml').read_text()\n",
    "        prompt_elements_dict = yaml.safe_load(prompt_elements_yaml).get(extraction_type)\n",
    "        method_goal = prompt_elements_dict['method goal']\n",
    "        methodology = prompt_elements_dict['methodology']\n",
    "        metadata_specs = prompt_elements_dict.get('metadata specs',[])\n",
    "        metadata_extraction_prompt_template = pts.get_prompt_template('metadata extraction (all questions, whole paper)').generate_chat_prompt_template()\n",
    "        extract_lcel = metadata_extraction_prompt_template | self.llm | JsonEnclosedByTextOutputParser()\n",
    "                \n",
    "        # 2. Run through all available sections of the paper and identify only those that are predominantly methods sections.\n",
    "        start = datetime.now()\n",
    "        fragments = [f.content for f in self.db.list_fragments_for_paper(paper_id, item_type, fragment_types=['section'])]\n",
    "        on_off = False\n",
    "        text = ''\n",
    "        for t in fragments:\n",
    "            l1 = t.split('\\n')[0].lower()\n",
    "            if 'method' in l1:\n",
    "                on_off = True\n",
    "            elif 'results' in l1 or 'discussion' in l1 or 'conclusion' in l1 or 'acknowledgements' in l1 \\\n",
    "                    or 'references' in l1 or 'supplementary' in l1 or 'appendix' in l1 or 'introduction' in l1 or 'abstract' in l1 or 'cited' in l1:\n",
    "                on_off = False\n",
    "            if on_off:\n",
    "                if len(text) > 0:\n",
    "                    text += '\\n\\n'\n",
    "                text += t\n",
    "\n",
    "        if len(text) == 0:\n",
    "            return {'answer': \"Could not retrieve full text of the paper: %s.\"%(paper_id),\n",
    "                \"data\": {'list_of_answers': None, 'run': run_metadata} }\n",
    "\n",
    "        # 3. Compile the extraction questions\n",
    "        question_text_list = [(\"%d. %s Record this value in the '%s' field of the output.\")\n",
    "                                %(i+1, spec.get('spec'), spec.get('name')) \n",
    "                                for i, spec in enumerate(metadata_specs)]\n",
    "        questions_output_specification = '\\n'.join(question_text_list)\n",
    "        questions_output_specification += '\\nGenerate only JSON formatted output with %d fields:\\n'%(len(metadata_specs))\n",
    "        questions_output_specification += \", \".join([spec.get('name') for spec in metadata_specs])\n",
    "\n",
    "        # 4. Assemble chain input\n",
    "        s1 = {'section_text': text,\n",
    "                'methodology': methodology,\n",
    "                'method_goal': method_goal,\n",
    "                'questions_output_specification': questions_output_specification}\n",
    "        \n",
    "        # 5. Run the chain with a JsonEnclosedByTextOutputParser \n",
    "        output = None\n",
    "        attempts = 0\n",
    "        full_answer = []\n",
    "        output = extract_lcel.invoke(s1)#, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "        total_execution_time = datetime.now() - start\n",
    "        time_per_variable = total_execution_time / len(metadata_specs)\n",
    "\n",
    "        if output is None:\n",
    "            return {'answer': \"attempted and failed metadata extraction for an experiment of type '%s' from %s.\"%(methodology, paper_id),\n",
    "                \"data\": {'list_of_answers': None, 'run': run_metadata} }\n",
    "\n",
    "        run_name = extraction_type+'__'+paper_id+'__'+run_label\n",
    "\n",
    "        n = Note(\n",
    "            id=uuid.uuid4().hex[0:10],\n",
    "            type='MetadataExtractionNote', \n",
    "            name=run_name,\n",
    "            provenance=json.dumps(run_metadata, indent=4),\n",
    "            content=json.dumps(output, indent=4), \n",
    "            creation_date=datetime.now(), \n",
    "            format='json')\n",
    "        n.is_about.append(ske)\n",
    "        self.db.session.add(n)\n",
    "        self.db.session.flush()\n",
    "                    \n",
    "        # commit the changes to the database\n",
    "        self.db.session.commit()\n",
    "        \n",
    "        return {'response': \"completed metadata extraction for an experiment of type '%s' from %s.\"%(methodology, paper_id),\n",
    "                \"data\": output, \n",
    "                'run': run_metadata} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MetadataExtraction_RAGOnSections_Tool(BaseMetadataExtractionTool):\n",
    "    '''Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'''\n",
    "    name = 'metadata_extraction'\n",
    "    description = 'Runs a specified metadata extraction pipeline over a research paper that has been loaded in the local literature database.'\n",
    "    \n",
    "    def _run(self, paper_id, extraction_type):\n",
    "        '''Runs the metadata extraction pipeline over the FullText of a specified paper.'''\n",
    "\n",
    "        if self.db.session is None:\n",
    "            session_class = sessionmaker(bind=self.db.engine)\n",
    "            self.db.session = session_class()\n",
    "\n",
    "        # 1. Load basic prompts and build vectorstore    \n",
    "        os.environ['PGVECTOR_CONNECTION_STRING'] = \"postgresql+psycopg2:///\"+self.db.name\n",
    "        vectorstore = PGVector.from_existing_index(\n",
    "                embedding = self.db.embed_model, \n",
    "                collection_name = 'ScienceKnowledgeItem_FullText') \n",
    "        if paper_id[0:4] != 'doi:':\n",
    "            paper_id = 'doi:'+paper_id\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={'filter': {'ske_id': paper_id}})\n",
    "\n",
    "        pts = PromptTemplateRegistry()\n",
    "        pts.load_prompts_from_yaml('metadata_extraction.yaml')\n",
    "        prompt_elements_yaml = files(prompt_elements).joinpath('metadata_extraction.yaml').read_text()\n",
    "        prompt_elements_dict = yaml.safe_load(prompt_elements_yaml).get(extraction_type)\n",
    "        method_goal = prompt_elements_dict['method goal']\n",
    "        methodology = prompt_elements_dict['methodology']\n",
    "        metadata_specs = prompt_elements_dict.get('metadata specs',[])\n",
    "        metadata_extraction_prompt_template = pts.get_prompt_template(\n",
    "            'metadata extraction (RAG over full text snippets)').generate_chat_prompt_template()\n",
    "        run_name = 'metadata_extraction_' + re.sub(' ','_',extraction_type) + ':' + paper_id\n",
    "\n",
    "        # 2. Iterate over questions to run extraction pipeline\n",
    "        full_answer = []\n",
    "        for i, spec in enumerate(metadata_specs):\n",
    "            question = spec.get('spec')\n",
    "            answer_spec = \"Record this value in the '%s' field of the output.\"%(spec.get('name')) \n",
    "            answer_spec += '\\nGenerate only JSON formatted output with one field\\n'\n",
    "            answer_spec += spec.get('name')\n",
    "\n",
    "            input = {'question': question,\n",
    "                'answer_specification': answer_spec,\n",
    "                'methodology': methodology,\n",
    "                'method_goal': method_goal}    \n",
    "            \n",
    "            qa_chain = (\n",
    "                RunnableParallel({\n",
    "                    \"question\": itemgetter(\"question\"),\n",
    "                    \"context\": itemgetter(\"question\") | retriever,\n",
    "                    \"answer_specification\": itemgetter(\"answer_specification\"),\n",
    "                    \"methodology\": itemgetter(\"methodology\"),\n",
    "                    \"method_goal\": itemgetter(\"method_goal\")\n",
    "                })\n",
    "                | {\n",
    "                    \"response\": metadata_extraction_prompt_template | self.llm | JsonEnclosedByTextOutputParser(),\n",
    "                    \"context\": itemgetter(\"context\"),\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # 5. Run the chain\n",
    "            output = qa_chain.invoke(input, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "            vname = spec.get('name')\n",
    "            question = spec.get('spec')\n",
    "            answer = output.get('response',{}).get(vname) \n",
    "            fragment_ids = []\n",
    "            for skf_id in [d.metadata.get('skf_id') for d in output.get('context', [])]:\n",
    "                fragment_ids.append(skf_id)\n",
    "                f = self.db.session.query(skf) \\\n",
    "                    .filter(skf.id == skf_id).first()\n",
    "                note_content = json.dumps({\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'variable': vname}, indent=4)\n",
    "                # add a note to the fragment\n",
    "                n = Note(id=uuid.uuid4().hex[0:10],\n",
    "                        type='MetadataExtractionNote__'+extraction_type, \n",
    "                        name=run_name+':'+vname,\n",
    "                        content=note_content, \n",
    "                        creation_date=datetime.now(), \n",
    "                        format='json')\n",
    "                n.is_about.append(f)\n",
    "                self.db.session.add(n)\n",
    "                self.db.session.flush()\n",
    "            self.db.session.commit()\n",
    "            full_answer.append({'variable_name': vname, 'question': question, 'fragment_ids': fragment_ids})\n",
    "        \n",
    "        return {'response': \"completed metadata extraction for an experiment of type '%s' from %s.\"%(methodology, paper_id),\n",
    "                \"data\": {'list_of_answers': full_answer, 'run_name': run_name} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SimpleExtractionWithRAGToolSchema(BaseModel):\n",
    "    paper_id: str = Field(description=\"The digitial object identifier (doi) of the paper being analyzed.\")\n",
    "    variable_name: str = Field(description=\"This is the variable that the question is attempting to extract from the paper.\")\n",
    "    question: str = Field(description=\"This is the question that must be answered to perform the extraction.\")\n",
    "\n",
    "class SimpleExtractionWithRAGTool(BaseTool, AlhazenToolMixin):\n",
    "    '''Performs simple information extraction from a specified research paper from the database.'''\n",
    "    name = 'simple_extraction'\n",
    "    description = 'Performs simple information extraction from a specified research paper from the database.'\n",
    "    args_schema = SimpleExtractionWithRAGToolSchema\n",
    "    \n",
    "    def _run(self, paper_id, variable_name, question ):\n",
    "        '''Runs the simple extraction pipeline over the FullText of a specified paper.'''\n",
    "\n",
    "        if self.db.session is None:\n",
    "            session_class = sessionmaker(bind=self.db.engine)\n",
    "            self.db.session = session_class()\n",
    "\n",
    "        # 1. Load basic prompts and build vectorstore    \n",
    "        os.environ['PGVECTOR_CONNECTION_STRING'] = \"postgresql+psycopg2:///\"+self.db.name\n",
    "        vectorstore = PGVector.from_existing_index(\n",
    "                embedding = self.db.embed_model, \n",
    "                collection_name = 'ScienceKnowledgeItem_FullText') \n",
    "        if paper_id[0:4] != 'doi:':\n",
    "            paper_id = 'doi:'+paper_id\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={'filter': {'ske_id': paper_id}})\n",
    "\n",
    "        pts = PromptTemplateRegistry()\n",
    "        pts.load_prompts_from_yaml('metadata_extraction.yaml')\n",
    "        simple_extraction_prompt_template = pts.get_prompt_template('simple extraction').generate_chat_prompt_template()\n",
    "\n",
    "        # 2. Iterate over questions to run extraction pipeline\n",
    "        full_answer = []\n",
    "        answer_spec = \"Record this value in the '%s' field of the output.\"%(variable_name) \n",
    "        answer_spec += '\\nGenerate only JSON formatted output.' \n",
    "\n",
    "        input = {'question': question, 'answer_specification': answer_spec}    \n",
    "            \n",
    "        qa_chain = (\n",
    "            RunnableParallel({\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"context\": itemgetter(\"question\") | retriever,\n",
    "                \"answer_specification\": itemgetter(\"answer_specification\"),\n",
    "            })\n",
    "            | {\n",
    "                \"response\": simple_extraction_prompt_template | self.llm | JsonEnclosedByTextOutputParser(),\n",
    "                \"context\": itemgetter(\"context\"),\n",
    "            }\n",
    "        )\n",
    "            \n",
    "        # 5. Run the chain\n",
    "        output = qa_chain.invoke(input, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "        answer = output.get('response',{}).get(variable_name) \n",
    "        fragment_ids = []\n",
    "        for skf_id in [d.metadata.get('skf_id') for d in output.get('context', [])]:\n",
    "            fragment_ids.append(skf_id)\n",
    "            f = self.db.session.query(skf) \\\n",
    "                .filter(skf.id == skf_id).first()\n",
    "            note_content = json.dumps({\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'variable': variable_name}, indent=4)\n",
    "            # add a note to the fragment\n",
    "            n = Note(id=uuid.uuid4().hex[0:10],\n",
    "                    type='NoteAboutFragment', \n",
    "                    name=paper_id+':'+variable_name,\n",
    "                    content=note_content, \n",
    "                    creation_date=datetime.now(), \n",
    "                    format='json')\n",
    "            n.is_about.append(f)\n",
    "            self.db.session.add(n)\n",
    "            self.db.session.flush()\n",
    "        self.db.session.commit()\n",
    "        full_answer = {'variable_name': variable_name, 'question': question, 'fragment_ids': fragment_ids}\n",
    "    \n",
    "        return {'response': \"I answered this question: `%s` concerning this variable: `%s` from %s.\"%(question, variable_name, paper_id),\n",
    "                \"data\": {'answer': full_answer }}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
